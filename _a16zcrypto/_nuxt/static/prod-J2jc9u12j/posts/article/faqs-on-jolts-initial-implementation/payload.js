__NUXT_JSONP__("/posts/article/faqs-on-jolts-initial-implementation", (function(a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X,Y,Z,_,$,aa,ab,ac,ad,ae,af,ag,ah,ai,aj,ak,al,am,an,ao,ap,aq,ar,as,at,au,av,aw,ax,ay,az,aA,aB,aC,aD,aE,aF,aG,aH,aI,aJ,aK,aL,aM,aN,aO,aP,aQ,aR,aS,aT,aU,aV,aW,aX,aY,aZ,a_,a$,ba,bb,bc,bd,be,bf,bg,bh,bi,bj,bk,bl,bm,bn,bo,bp,bq,br,bs,bt,bu,bv,bw,bx,by,bz,bA,bB,bC,bD,bE,bF,bG,bH,bI,bJ,bK,bL,bM,bN,bO,bP,bQ,bR,bS,bT,bU,bV,bW,bX,bY,bZ,b_,b$,ca,cb,cc,cd,ce,cf,cg,ch,ci,cj,ck,cl,cm,cn,co,cp,cq,cr,cs,ct,cu,cv,cw,cx,cy,cz,cA,cB,cC,cD,cE,cF,cG,cH,cI,cJ,cK,cL,cM,cN,cO,cP,cQ,cR,cS,cT,cU,cV,cW,cX,cY,cZ,c_,c$,da,db,dc,dd,de,df,dg,dh,di,dj,dk,dl,dm,dn,do0,dp,dq,dr,ds,dt,du,dv,dw,dx,dy,dz,dA,dB,dC,dD,dE,dF,dG,dH,dI,dJ,dK,dL,dM,dN,dO,dP,dQ,dR,dS,dT,dU,dV,dW,dX,dY,dZ,d_,d$,ea,eb,ec,ed,ee,ef,eg,eh,ei,ej,ek,el,em,en,eo,ep,eq,er,es,et,eu,ev,ew,ex,ey,ez,eA,eB,eC){cd.favicon=d;cd.other_icons=d;cd.newsletter_title="newsletter: web3 weekly";cd.newsletter_subtitle="A newsletter from a16z crypto, and your go-to guide to the next internet";cd.newsletter_input_placeholder=ce;cd.newsletter_button_text=ce;cd.podcast_title="podcast: web3 with a16z";cd.podcast_subtitle="A show about building the next internet, from a16z crypto";cd.follow_us_text="Follow us";cd.logo=d;cd.disclaimer="Any investments or portfolio companies mentioned, referred to, or described on this page are not representative of all investments in vehicles managed by a16z and there can be no assurance that the investments will be profitable or that other investments made in the future will have similar characteristics or results. Exits include current and former a16z portfolio companies which have been acquired as well as companies which have undergone an initial public offering or direct public offering of shares. Certain publicly traded companies on this list may still be held in Andreessen Horowitz funds. A list of investments made by funds managed by a16z is available here: https:\u002F\u002Fa16z.com\u002Finvestments\u002F. Excluded from this list are investments for which the issuer has not provided permission for a16z to disclose publicly as well as unannounced investments in publicly traded digital assets. Further, the list of investments is updated monthly and as such may not reflect most recent a16z investments. Past results of Andreessen Horowitz’s investments, pooled investment vehicles, or investment strategies are not necessarily indicative of future results.";cd.copyright="&copy; 2024 Andreessen Horowitz";cd.footer_menu=cf;cd.cookie_banner_text="we use third party cookies in order to personalise your site experience";cd.socials=cg;cd.streaming=ch;cd.header_newsletter_title="Newsletter Sign Up";cd.header_newsletter_input_placeholder="enter email address";cd.header_newsletter_button_text="subscribe";cd.header_socials=d;cd.nav_focus_area_label_text="FOCUS AREAS";cd.nav_focus_areas=[{term_id:a,name:"company building",slug:"company-building",term_group:c,term_taxonomy_id:a,taxonomy:aq,description:b,parent:c,count:196,filter:m,url:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fposts\u002Ffocus-areas\u002Fcompany-building\u002F"},{term_id:ci,name:"tech trends",slug:"tech-trends",term_group:c,term_taxonomy_id:ci,taxonomy:aq,description:b,parent:c,count:236,filter:m,url:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fposts\u002Ffocus-areas\u002Ftech-trends\u002F"},{term_id:cj,name:"policy &amp; regulation",slug:aB,term_group:c,term_taxonomy_id:cj,taxonomy:aq,description:b,parent:c,count:158,filter:m,url:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fposts\u002Ffocus-areas\u002Fpolicy\u002F"},{term_id:az,name:r,slug:r,term_group:c,term_taxonomy_id:az,taxonomy:aq,description:b,parent:c,count:bt,filter:m,url:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fposts\u002Ffocus-areas\u002Fresearch\u002F"},{term_id:ck,name:"code &amp; engineering",slug:"code-engineering",term_group:c,term_taxonomy_id:ck,taxonomy:aq,description:b,parent:c,count:42,filter:m,url:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fposts\u002Ffocus-areas\u002Fcode-engineering\u002F"}];cd.nav_trending_topics_label_text="TRENDING TOPICS";cd.nav_trending_topics=[{term_id:cl,name:cm,slug:cm,term_group:c,term_taxonomy_id:cl,taxonomy:an,description:b,parent:c,count:ca,filter:m,url:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fposts\u002Ftags\u002Fdecentralization\u002F"},{term_id:cn,name:"zero knowledge",slug:"zkps-zero-knowledge-proofs-systems-more",term_group:c,term_taxonomy_id:cn,taxonomy:an,description:b,parent:c,count:36,filter:m,url:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fposts\u002Ftags\u002Fzkps-zero-knowledge-proofs-systems-more\u002F"},{term_id:co,name:cp,slug:cp,term_group:c,term_taxonomy_id:co,taxonomy:an,description:b,parent:c,count:43,filter:m,url:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fposts\u002Ftags\u002Fsecurity\u002F"}];cd.view_all_content_button={title:"view all content",url:"\u002Fcontent\u002F",target:b};cd.enable_puzzle=h;cd.puzzle_code_1=cq;cd.puzzle_code_2=cr;cd.header_css_js_custom="table#releasenotes {\r\n  width: 100% !important;\r\n  border-collapse: collapse ;\r\n  border: 3px solid purple;\r\n}\r\n\r\ntable#releasenotes td {\r\n  width: 50% !important;\r\n  border: 1px black solid ;\r\n  padding: 10px ;\r\n}\r\n\r\ndiv.punch-viewer-navbar-logo {\r\n  display: hidden !important;\r\n}";cd.custom_js_footer=b;cd.header_button=b;cd.companies_eyebrow="CSX COMPANIES";cd.companies_title=b;cd.companies_stats=d;cd.companies_companies=[{company_name:aT,square_logo:{ID:cs,id:cs,title:aT,filename:"afriex.svg",filesize:907,url:s,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fafriex\u002F",alt:b,author:k,description:b,caption:b,name:aT,status:e,uploaded_to:c,date:ct,modified:ct,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:s,"thumbnail-width":a,"thumbnail-height":a,medium:s,"medium-width":a,"medium-height":a,medium_large:s,"medium_large-width":a,"medium_large-height":a,large:s,"large-width":a,"large-height":a,"1536x1536":s,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":s,"2048x2048-width":a,"2048x2048-height":a,"medium-size":s,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"https:\u002F\u002Fwww.afriexapp.com\u002F"},{company_name:aU,square_logo:{ID:cu,id:cu,title:aU,filename:"axal.svg",filesize:1117,url:t,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Faxal\u002F",alt:b,author:k,description:b,caption:b,name:aU,status:e,uploaded_to:c,date:cv,modified:cv,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:t,"thumbnail-width":a,"thumbnail-height":a,medium:t,"medium-width":a,"medium-height":a,medium_large:t,"medium_large-width":a,"medium_large-height":a,large:t,"large-width":a,"large-height":a,"1536x1536":t,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":t,"2048x2048-width":a,"2048x2048-height":a,"medium-size":t,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"https:\u002F\u002Fax.al"},{company_name:aV,square_logo:{ID:cw,id:cw,title:aV,filename:"bello.svg",filesize:8224,url:u,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fbello\u002F",alt:b,author:k,description:b,caption:b,name:aV,status:e,uploaded_to:c,date:cx,modified:cx,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:u,"thumbnail-width":a,"thumbnail-height":a,medium:u,"medium-width":a,"medium-height":a,medium_large:u,"medium_large-width":a,"medium_large-height":a,large:u,"large-width":a,"large-height":a,"1536x1536":u,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":u,"2048x2048-width":a,"2048x2048-height":a,"medium-size":u,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"https:\u002F\u002Fbello.lol\u002F"},{company_name:aW,square_logo:{ID:cy,id:cy,title:aW,filename:"blockus.png",filesize:12591,url:at,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fblockus\u002F",alt:b,author:k,description:b,caption:b,name:aW,status:e,uploaded_to:c,date:cz,modified:cz,menu_order:c,mime_type:cA,type:f,subtype:cB,icon:g,width:ar,height:au,sizes:{thumbnail:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Fblockus-150x150.png","thumbnail-width":aC,"thumbnail-height":aC,medium:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Fblockus-259x300.png","medium-width":259,"medium-height":cC,medium_large:at,"medium_large-width":ar,"medium_large-height":au,large:at,"large-width":ar,"large-height":au,"1536x1536":at,"1536x1536-width":ar,"1536x1536-height":au,"2048x2048":at,"2048x2048-width":ar,"2048x2048-height":au,"medium-size":"https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Fblockus-369x400.png","medium-size-width":ar,"medium-size-height":cD}},full_logo:d,x:b,linkedin:b,website:"https:\u002F\u002Fwww.blockus.gg\u002F"},{company_name:aX,square_logo:{ID:cE,id:cE,title:aX,filename:"capsule.svg",filesize:1539,url:v,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fcapsule\u002F",alt:b,author:k,description:b,caption:b,name:aX,status:e,uploaded_to:c,date:cF,modified:cF,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:v,"thumbnail-width":a,"thumbnail-height":a,medium:v,"medium-width":a,"medium-height":a,medium_large:v,"medium_large-width":a,"medium_large-height":a,large:v,"large-width":a,"large-height":a,"1536x1536":v,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":v,"2048x2048-width":a,"2048x2048-height":a,"medium-size":v,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"https:\u002F\u002Fusecapsule.com\u002F"},{company_name:"Chain Patrol",square_logo:{ID:cG,id:cG,title:cH,filename:"chainpatrol.svg",filesize:16389,url:w,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fchainpatrol\u002F",alt:b,author:k,description:b,caption:b,name:cH,status:e,uploaded_to:c,date:cI,modified:cI,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:w,"thumbnail-width":a,"thumbnail-height":a,medium:w,"medium-width":a,"medium-height":a,medium_large:w,"medium_large-width":a,"medium_large-height":a,large:w,"large-width":a,"large-height":a,"1536x1536":w,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":w,"2048x2048-width":a,"2048x2048-height":a,"medium-size":w,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"https:\u002F\u002Fchainpatrol.io\u002F"},{company_name:"Collar Networks",square_logo:{ID:cJ,id:cJ,title:"Collar_Wordmark_Yellow - Michael Moulton",filename:"Collar_Wordmark_Yellow-Michael-Moulton.svg",filesize:12535,url:x,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fcollar_wordmark_yellow-michael-moulton\u002F",alt:b,author:o,description:b,caption:b,name:"collar_wordmark_yellow-michael-moulton",status:e,uploaded_to:c,date:cK,modified:cK,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:x,"thumbnail-width":a,"thumbnail-height":a,medium:x,"medium-width":a,"medium-height":a,medium_large:x,"medium_large-width":a,"medium_large-height":a,large:x,"large-width":a,"large-height":a,"1536x1536":x,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":x,"2048x2048-width":a,"2048x2048-height":a,"medium-size":x,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:b},{company_name:"Compass Labs",square_logo:{ID:cL,id:cL,title:"logo_nooutline_width60 (1) - Elisabeth Duijnstee",filename:"logo_nooutline_width60-1-Elisabeth-Duijnstee.svg",filesize:1408,url:y,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Flogo_nooutline_width60-1-elisabeth-duijnstee\u002F",alt:b,author:o,description:b,caption:b,name:"logo_nooutline_width60-1-elisabeth-duijnstee",status:e,uploaded_to:c,date:cM,modified:cM,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:y,"thumbnail-width":a,"thumbnail-height":a,medium:y,"medium-width":a,"medium-height":a,medium_large:y,"medium_large-width":a,"medium_large-height":a,large:y,"large-width":a,"large-height":a,"1536x1536":y,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":y,"2048x2048-width":a,"2048x2048-height":a,"medium-size":y,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"https:\u002F\u002Fwww.compasslabs.ai\u002F"},{company_name:"Discove",square_logo:{ID:cN,id:cN,title:cO,filename:"discove.svg",filesize:4541,url:z,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fdiscove\u002F",alt:b,author:k,description:b,caption:b,name:cO,status:e,uploaded_to:c,date:cP,modified:cP,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:z,"thumbnail-width":a,"thumbnail-height":a,medium:z,"medium-width":a,"medium-height":a,medium_large:z,"medium_large-width":a,"medium_large-height":a,large:z,"large-width":a,"large-height":a,"1536x1536":z,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":z,"2048x2048-width":a,"2048x2048-height":a,"medium-size":z,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"https:\u002F\u002Fdiscove.xyz"},{company_name:"EthXY",square_logo:{ID:cQ,id:cQ,title:"ethxy-dark - J Eth",filename:"ethxy-dark-J-Eth.svg",filesize:19156,url:A,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fethxy-dark-j-eth\u002F",alt:b,author:o,description:b,caption:b,name:"ethxy-dark-j-eth",status:e,uploaded_to:c,date:cR,modified:cR,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:A,"thumbnail-width":a,"thumbnail-height":a,medium:A,"medium-width":a,"medium-height":a,medium_large:A,"medium_large-width":a,"medium_large-height":a,large:A,"large-width":a,"large-height":a,"1536x1536":A,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":A,"2048x2048-width":a,"2048x2048-height":a,"medium-size":A,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"https:\u002F\u002Fethxy.com"},{company_name:aY,square_logo:{ID:cS,id:cS,title:aY,filename:"id.svg",filesize:2287,url:B,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fid\u002F",alt:b,author:k,description:b,caption:b,name:aY,status:e,uploaded_to:c,date:cT,modified:cT,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:B,"thumbnail-width":a,"thumbnail-height":a,medium:B,"medium-width":a,"medium-height":a,medium_large:B,"medium_large-width":a,"medium_large-height":a,large:B,"large-width":a,"large-height":a,"1536x1536":B,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":B,"2048x2048-width":a,"2048x2048-height":a,"medium-size":B,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:b},{company_name:"Fan Craze",square_logo:{ID:cU,id:cU,title:cV,filename:"fancraze.svg",filesize:1051,url:C,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Ffancraze\u002F",alt:b,author:k,description:b,caption:b,name:cV,status:e,uploaded_to:c,date:cW,modified:cW,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:C,"thumbnail-width":a,"thumbnail-height":a,medium:C,"medium-width":a,"medium-height":a,medium_large:C,"medium_large-width":a,"medium_large-height":a,large:C,"large-width":a,"large-height":a,"1536x1536":C,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":C,"2048x2048-width":a,"2048x2048-height":a,"medium-size":C,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"https:\u002F\u002Fwww.fancraze.com\u002F"},{company_name:"FINE",square_logo:{ID:cX,id:cX,title:cY,filename:"fine.svg",filesize:848,url:D,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Ffine\u002F",alt:b,author:k,description:b,caption:b,name:cY,status:e,uploaded_to:c,date:cZ,modified:cZ,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:D,"thumbnail-width":a,"thumbnail-height":a,medium:D,"medium-width":a,"medium-height":a,medium_large:D,"medium_large-width":a,"medium_large-height":a,large:D,"large-width":a,"large-height":a,"1536x1536":D,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":D,"2048x2048-width":a,"2048x2048-height":a,"medium-size":D,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:b},{company_name:aZ,square_logo:{ID:c_,id:c_,title:aZ,filename:"flashbot.svg",filesize:1011,url:E,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fflashbot\u002F",alt:b,author:k,description:b,caption:b,name:aZ,status:e,uploaded_to:c,date:c$,modified:c$,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:E,"thumbnail-width":a,"thumbnail-height":a,medium:E,"medium-width":a,"medium-height":a,medium_large:E,"medium_large-width":a,"medium_large-height":a,large:E,"large-width":a,"large-height":a,"1536x1536":E,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":E,"2048x2048-width":a,"2048x2048-height":a,"medium-size":E,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:b},{company_name:"Formless",square_logo:{ID:da,id:da,title:db,filename:"formless.svg",filesize:1233,url:F,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fformless\u002F",alt:b,author:k,description:b,caption:b,name:db,status:e,uploaded_to:c,date:dc,modified:dc,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:F,"thumbnail-width":a,"thumbnail-height":a,medium:F,"medium-width":a,"medium-height":a,medium_large:F,"medium_large-width":a,"medium_large-height":a,large:F,"large-width":a,"large-height":a,"1536x1536":F,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":F,"2048x2048-width":a,"2048x2048-height":a,"medium-size":F,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"https:\u002F\u002Fformless.xyz"},{company_name:"Frens",square_logo:{ID:dd,id:dd,title:de,filename:"frens.svg",filesize:876,url:G,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Ffrens\u002F",alt:b,author:k,description:b,caption:b,name:de,status:e,uploaded_to:c,date:df,modified:df,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:G,"thumbnail-width":a,"thumbnail-height":a,medium:G,"medium-width":a,"medium-height":a,medium_large:G,"medium_large-width":a,"medium_large-height":a,large:G,"large-width":a,"large-height":a,"1536x1536":G,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":G,"2048x2048-width":a,"2048x2048-height":a,"medium-size":G,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"frens.lol"},{company_name:"Fuul",square_logo:{ID:dg,id:dg,title:dh,filename:"fuul.svg",filesize:3228,url:H,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Ffuul\u002F",alt:b,author:k,description:b,caption:b,name:dh,status:e,uploaded_to:c,date:di,modified:di,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:H,"thumbnail-width":a,"thumbnail-height":a,medium:H,"medium-width":a,"medium-height":a,medium_large:H,"medium_large-width":a,"medium_large-height":a,large:H,"large-width":a,"large-height":a,"1536x1536":H,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":H,"2048x2048-width":a,"2048x2048-height":a,"medium-size":H,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"http:\u002F\u002Fwww.fuul.xyz"},{company_name:a_,square_logo:{ID:dj,id:dj,title:a_,filename:"gandalf.svg",filesize:1634,url:I,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fgandalf\u002F",alt:b,author:k,description:b,caption:b,name:a_,status:e,uploaded_to:c,date:dk,modified:dk,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:I,"thumbnail-width":a,"thumbnail-height":a,medium:I,"medium-width":a,"medium-height":a,medium_large:I,"medium_large-width":a,"medium_large-height":a,large:I,"large-width":a,"large-height":a,"1536x1536":I,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":I,"2048x2048-width":a,"2048x2048-height":a,"medium-size":I,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"https:\u002F\u002Fgandalf.network\u002F"},{company_name:"Goldfinch",square_logo:{ID:dl,id:dl,title:"goldfinch",filename:"goldfinch.svg",filesize:3085,url:J,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fgoldfinch-2\u002F",alt:b,author:k,description:b,caption:b,name:"goldfinch-2",status:e,uploaded_to:c,date:dm,modified:dm,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:J,"thumbnail-width":a,"thumbnail-height":a,medium:J,"medium-width":a,"medium-height":a,medium_large:J,"medium_large-width":a,"medium_large-height":a,large:J,"large-width":a,"large-height":a,"1536x1536":J,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":J,"2048x2048-width":a,"2048x2048-height":a,"medium-size":J,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"https:\u002F\u002Fgoldfinch.finance\u002F"},{company_name:a$,square_logo:{ID:dn,id:dn,title:a$,filename:"iyk.svg",filesize:758,url:K,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fiyk\u002F",alt:b,author:k,description:b,caption:b,name:a$,status:e,uploaded_to:c,date:do0,modified:do0,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:K,"thumbnail-width":a,"thumbnail-height":a,medium:K,"medium-width":a,"medium-height":a,medium_large:K,"medium_large-width":a,"medium_large-height":a,large:K,"large-width":a,"large-height":a,"1536x1536":K,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":K,"2048x2048-width":a,"2048x2048-height":a,"medium-size":K,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"https:\u002F\u002Fiyk.app\u002F"},{company_name:dp,square_logo:{ID:dq,id:dq,title:dp,filename:"kiki.svg",filesize:1785,url:L,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fkiki-2\u002F",alt:b,author:k,description:b,caption:b,name:"kiki-2",status:e,uploaded_to:c,date:dr,modified:dr,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:L,"thumbnail-width":a,"thumbnail-height":a,medium:L,"medium-width":a,"medium-height":a,medium_large:L,"medium_large-width":a,"medium_large-height":a,large:L,"large-width":a,"large-height":a,"1536x1536":L,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":L,"2048x2048-width":a,"2048x2048-height":a,"medium-size":L,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"https:\u002F\u002Fwww.kiki.world\u002F"},{company_name:"Magicblock",square_logo:{ID:ds,id:ds,title:"magicblock_white (1) - Andrea Fortugno",filename:"magicblock_white-1-Andrea-Fortugno.svg",filesize:9784,url:M,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fmagicblock_white-1-andrea-fortugno\u002F",alt:b,author:o,description:b,caption:b,name:"magicblock_white-1-andrea-fortugno",status:e,uploaded_to:c,date:dt,modified:dt,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:M,"thumbnail-width":a,"thumbnail-height":a,medium:M,"medium-width":a,"medium-height":a,medium_large:M,"medium_large-width":a,"medium_large-height":a,large:M,"large-width":a,"large-height":a,"1536x1536":M,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":M,"2048x2048-width":a,"2048x2048-height":a,"medium-size":M,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"https:\u002F\u002Fwww.magicblock.gg\u002F"},{company_name:ba,square_logo:{ID:du,id:du,title:ba,filename:"mbd.svg",filesize:2670,url:N,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fmbd\u002F",alt:b,author:k,description:b,caption:b,name:ba,status:e,uploaded_to:c,date:aD,modified:aD,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:N,"thumbnail-width":a,"thumbnail-height":a,medium:N,"medium-width":a,"medium-height":a,medium_large:N,"medium_large-width":a,"medium_large-height":a,large:N,"large-width":a,"large-height":a,"1536x1536":N,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":N,"2048x2048-width":a,"2048x2048-height":a,"medium-size":N,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:b},{company_name:bb,square_logo:{ID:dv,id:dv,title:bb,filename:"mentaport.svg",filesize:878,url:O,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fmentaport\u002F",alt:b,author:k,description:b,caption:b,name:bb,status:e,uploaded_to:c,date:aD,modified:aD,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:O,"thumbnail-width":a,"thumbnail-height":a,medium:O,"medium-width":a,"medium-height":a,medium_large:O,"medium_large-width":a,"medium_large-height":a,large:O,"large-width":a,"large-height":a,"1536x1536":O,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":O,"2048x2048-width":a,"2048x2048-height":a,"medium-size":O,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"https:\u002F\u002Fwww.mentaport.com\u002F"},{company_name:bc,square_logo:{ID:dw,id:dw,title:bc,filename:"mir.svg",filesize:1130,url:P,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fmir\u002F",alt:b,author:k,description:b,caption:b,name:bc,status:e,uploaded_to:c,date:aE,modified:aE,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:P,"thumbnail-width":a,"thumbnail-height":a,medium:P,"medium-width":a,"medium-height":a,medium_large:P,"medium_large-width":a,"medium_large-height":a,large:P,"large-width":a,"large-height":a,"1536x1536":P,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":P,"2048x2048-width":a,"2048x2048-height":a,"medium-size":P,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:b},{company_name:bd,square_logo:{ID:dx,id:dx,title:bd,filename:"narval.svg",filesize:3111,url:Q,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fnarval\u002F",alt:b,author:k,description:b,caption:b,name:bd,status:e,uploaded_to:c,date:aE,modified:aE,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:Q,"thumbnail-width":a,"thumbnail-height":a,medium:Q,"medium-width":a,"medium-height":a,medium_large:Q,"medium_large-width":a,"medium_large-height":a,large:Q,"large-width":a,"large-height":a,"1536x1536":Q,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":Q,"2048x2048-width":a,"2048x2048-height":a,"medium-size":Q,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"http:\u002F\u002Fnarval.xyz"},{company_name:"Nebra",square_logo:{ID:dy,id:dy,title:"NEBRA_logo_1 - Shumo Chu",filename:"NEBRA_logo_1-Shumo-Chu.svg",filesize:2102,url:R,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fnebra_logo_1-shumo-chu\u002F",alt:b,author:o,description:b,caption:b,name:"nebra_logo_1-shumo-chu",status:e,uploaded_to:c,date:dz,modified:dz,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:R,"thumbnail-width":a,"thumbnail-height":a,medium:R,"medium-width":a,"medium-height":a,medium_large:R,"medium_large-width":a,"medium_large-height":a,large:R,"large-width":a,"large-height":a,"1536x1536":R,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":R,"2048x2048-width":a,"2048x2048-height":a,"medium-size":R,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"nebra.one"},{company_name:"Neynar",square_logo:{ID:dA,id:dA,title:"Frame 27 - Rishav Mukherji",filename:"Frame-27-Rishav-Mukherji.svg",filesize:4170,url:S,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fframe-27-rishav-mukherji\u002F",alt:b,author:o,description:b,caption:b,name:"frame-27-rishav-mukherji",status:e,uploaded_to:c,date:dB,modified:dB,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:S,"thumbnail-width":a,"thumbnail-height":a,medium:S,"medium-width":a,"medium-height":a,medium_large:S,"medium_large-width":a,"medium_large-height":a,large:S,"large-width":a,"large-height":a,"1536x1536":S,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":S,"2048x2048-width":a,"2048x2048-height":a,"medium-size":S,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"http:\u002F\u002Fneynar.com"},{company_name:"Nodekit",square_logo:{ID:dC,id:dC,title:"NodeKit Logo - Atomic Abyss (1) - Nick Preszler",filename:"NodeKit-Logo-Atomic-Abyss-1-Nick-Preszler.svg",filesize:4216,url:T,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fnodekit-logo-atomic-abyss-1-nick-preszler\u002F",alt:b,author:o,description:b,caption:b,name:"nodekit-logo-atomic-abyss-1-nick-preszler",status:e,uploaded_to:c,date:dD,modified:dD,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:T,"thumbnail-width":a,"thumbnail-height":a,medium:T,"medium-width":a,"medium-height":a,medium_large:T,"medium_large-width":a,"medium_large-height":a,large:T,"large-width":a,"large-height":a,"1536x1536":T,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":T,"2048x2048-width":a,"2048x2048-height":a,"medium-size":T,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"http:\u002F\u002Fnodekit.xyz"},{company_name:"notional finance",square_logo:{ID:dE,id:dE,title:dF,filename:"notion-finance.svg",filesize:1843,url:U,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fnotion-finance\u002F",alt:b,author:k,description:b,caption:b,name:dF,status:e,uploaded_to:c,date:aF,modified:aF,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:U,"thumbnail-width":a,"thumbnail-height":a,medium:U,"medium-width":a,"medium-height":a,medium_large:U,"medium_large-width":a,"medium_large-height":a,large:U,"large-width":a,"large-height":a,"1536x1536":U,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":U,"2048x2048-width":a,"2048x2048-height":a,"medium-size":U,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"https:\u002F\u002Fnotional.finance\u002F"},{company_name:"OpenTrade",square_logo:{ID:dG,id:dG,title:"OpenTrade-logo (2) - David Sutter",filename:"OpenTrade-logo-2-David-Sutter.svg",filesize:4133,url:V,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fopentrade-logo-2-david-sutter\u002F",alt:b,author:o,description:b,caption:b,name:"opentrade-logo-2-david-sutter",status:e,uploaded_to:c,date:dH,modified:dH,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:V,"thumbnail-width":a,"thumbnail-height":a,medium:V,"medium-width":a,"medium-height":a,medium_large:V,"medium_large-width":a,"medium_large-height":a,large:V,"large-width":a,"large-height":a,"1536x1536":V,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":V,"2048x2048-width":a,"2048x2048-height":a,"medium-size":V,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"https:\u002F\u002Fwww.opentrade.io\u002F"},{company_name:dI,square_logo:{ID:dJ,id:dJ,title:dI,filename:"phantom.svg",filesize:1842,url:W,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fphantom-2\u002F",alt:b,author:k,description:b,caption:b,name:"phantom-2",status:e,uploaded_to:c,date:aF,modified:aF,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:W,"thumbnail-width":a,"thumbnail-height":a,medium:W,"medium-width":a,"medium-height":a,medium_large:W,"medium_large-width":a,"medium_large-height":a,large:W,"large-width":a,"large-height":a,"1536x1536":W,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":W,"2048x2048-width":a,"2048x2048-height":a,"medium-size":W,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"https:\u002F\u002Fphantom.app\u002F"},{company_name:dK,square_logo:{ID:dL,id:dL,title:dK,filename:"pimlico.svg",filesize:4377,url:X,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fpimlico-2\u002F",alt:b,author:k,description:b,caption:b,name:"pimlico-2",status:e,uploaded_to:c,date:aG,modified:aG,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:X,"thumbnail-width":a,"thumbnail-height":a,medium:X,"medium-width":a,"medium-height":a,medium_large:X,"medium_large-width":a,"medium_large-height":a,large:X,"large-width":a,"large-height":a,"1536x1536":X,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":X,"2048x2048-width":a,"2048x2048-height":a,"medium-size":X,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"https:\u002F\u002Fwww.pimlico.io\u002F"},{company_name:"Playmint",square_logo:{ID:dM,id:dM,title:"Playmint_Logo_Export_Colour_Black - Luke Gibson",filename:"Playmint_Logo_Export_Colour_Black-Luke-Gibson.svg",filesize:6812,url:Y,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fcsx\u002Fplaymint_logo_export_colour_black-luke-gibson\u002F",alt:b,author:o,description:b,caption:b,name:"playmint_logo_export_colour_black-luke-gibson",status:e,uploaded_to:dN,date:"2024-09-03 23:34:57",modified:"2024-09-04 22:32:11",menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:Y,"thumbnail-width":a,"thumbnail-height":a,medium:Y,"medium-width":a,"medium-height":a,medium_large:Y,"medium_large-width":a,"medium_large-height":a,large:Y,"large-width":a,"large-height":a,"1536x1536":Y,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":Y,"2048x2048-width":a,"2048x2048-height":a,"medium-size":Y,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"https:\u002F\u002Fplaymint.com\u002F"},{company_name:be,square_logo:{ID:dO,id:dO,title:be,filename:"primev.svg",filesize:1684,url:Z,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fprimev\u002F",alt:b,author:k,description:b,caption:b,name:be,status:e,uploaded_to:c,date:aG,modified:aG,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:Z,"thumbnail-width":a,"thumbnail-height":a,medium:Z,"medium-width":a,"medium-height":a,medium_large:Z,"medium_large-width":a,"medium_large-height":a,large:Z,"large-width":a,"large-height":a,"1536x1536":Z,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":Z,"2048x2048-width":a,"2048x2048-height":a,"medium-size":Z,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"https:\u002F\u002Fprimev.xyz\u002F"},{company_name:"Roux",square_logo:{ID:dP,id:dP,title:"Roux_logo_castiron - Lisa Grimm",filename:"Roux_logo_castiron-Lisa-Grimm.svg",filesize:36761,url:_,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fcsx\u002Froux_logo_castiron-lisa-grimm\u002F",alt:b,author:o,description:b,caption:b,name:"roux_logo_castiron-lisa-grimm",status:e,uploaded_to:dN,date:"2024-09-03 23:35:45",modified:"2024-09-04 22:32:12",menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:_,"thumbnail-width":a,"thumbnail-height":a,medium:_,"medium-width":a,"medium-height":a,medium_large:_,"medium_large-width":a,"medium_large-height":a,large:_,"large-width":a,"large-height":a,"1536x1536":_,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":_,"2048x2048-width":a,"2048x2048-height":a,"medium-size":_,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"www.roux.app"},{company_name:bf,square_logo:{ID:dQ,id:dQ,title:bf,filename:"shield.svg",filesize:2662,url:$,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fshield\u002F",alt:b,author:k,description:b,caption:b,name:bf,status:e,uploaded_to:c,date:aH,modified:aH,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:$,"thumbnail-width":a,"thumbnail-height":a,medium:$,"medium-width":a,"medium-height":a,medium_large:$,"medium_large-width":a,"medium_large-height":a,large:$,"large-width":a,"large-height":a,"1536x1536":$,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":$,"2048x2048-width":a,"2048x2048-height":a,"medium-size":$,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"http:\u002F\u002Fgetshield.xyz"},{company_name:"Siren",square_logo:{ID:dR,id:dR,title:"siren_Logo_black (1) - Andrei Anisimov",filename:"siren_Logo_black-1-Andrei-Anisimov.svg",filesize:2329,url:aa,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fsiren_logo_black-1-andrei-anisimov\u002F",alt:b,author:o,description:b,caption:b,name:"siren_logo_black-1-andrei-anisimov",status:e,uploaded_to:c,date:dS,modified:dS,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:aa,"thumbnail-width":a,"thumbnail-height":a,medium:aa,"medium-width":a,"medium-height":a,medium_large:aa,"medium_large-width":a,"medium_large-height":a,large:aa,"large-width":a,"large-height":a,"1536x1536":aa,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":aa,"2048x2048-width":a,"2048x2048-height":a,"medium-size":aa,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"https:\u002F\u002Fsiren.xyz\u002F"},{company_name:bg,square_logo:{ID:dT,id:dT,title:bg,filename:"skylab.svg",filesize:2674,url:ab,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fskylab\u002F",alt:b,author:k,description:b,caption:b,name:bg,status:e,uploaded_to:c,date:aH,modified:aH,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:ab,"thumbnail-width":a,"thumbnail-height":a,medium:ab,"medium-width":a,"medium-height":a,medium_large:ab,"medium_large-width":a,"medium_large-height":a,large:ab,"large-width":a,"large-height":a,"1536x1536":ab,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":ab,"2048x2048-width":a,"2048x2048-height":a,"medium-size":ab,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"https:\u002F\u002Fwww.skylab.xyz\u002F"},{company_name:"Spire",square_logo:{ID:dU,id:dU,title:"transparent - Kaito Yanai",filename:"transparent-Kaito-Yanai.svg",filesize:2085,url:ac,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Ftransparent-kaito-yanai\u002F",alt:b,author:o,description:b,caption:b,name:"transparent-kaito-yanai",status:e,uploaded_to:c,date:dV,modified:dV,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:ac,"thumbnail-width":a,"thumbnail-height":a,medium:ac,"medium-width":a,"medium-height":a,medium_large:ac,"medium_large-width":a,"medium_large-height":a,large:ac,"large-width":a,"large-height":a,"1536x1536":ac,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":ac,"2048x2048-width":a,"2048x2048-height":a,"medium-size":ac,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"https:\u002F\u002Fwww.spire.dev\u002F"},{company_name:bh,square_logo:{ID:dW,id:dW,title:bh,filename:"spring.svg",filesize:13520,url:ad,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fspring\u002F",alt:b,author:k,description:b,caption:b,name:bh,status:e,uploaded_to:c,date:aI,modified:aI,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:ad,"thumbnail-width":a,"thumbnail-height":a,medium:ad,"medium-width":a,"medium-height":a,medium_large:ad,"medium_large-width":a,"medium_large-height":a,large:ad,"large-width":a,"large-height":a,"1536x1536":ad,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":ad,"2048x2048-width":a,"2048x2048-height":a,"medium-size":ad,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"https:\u002F\u002Fspringinafrica.com"},{company_name:bi,square_logo:{ID:dX,id:dX,title:bi,filename:"stackr.svg",filesize:4351,url:ae,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fstackr\u002F",alt:b,author:k,description:b,caption:b,name:bi,status:e,uploaded_to:c,date:aI,modified:aI,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:ae,"thumbnail-width":a,"thumbnail-height":a,medium:ae,"medium-width":a,"medium-height":a,medium_large:ae,"medium_large-width":a,"medium_large-height":a,large:ae,"large-width":a,"large-height":a,"1536x1536":ae,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":ae,"2048x2048-width":a,"2048x2048-height":a,"medium-size":ae,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"https:\u002F\u002Fwww.stackrlabs.xyz"},{company_name:dY,square_logo:{ID:dZ,id:dZ,title:dY,filename:"teller-1.svg",filesize:1081,url:af,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fteller-2\u002F",alt:b,author:k,description:b,caption:b,name:"teller-2",status:e,uploaded_to:c,date:aJ,modified:aJ,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:af,"thumbnail-width":a,"thumbnail-height":a,medium:af,"medium-width":a,"medium-height":a,medium_large:af,"medium_large-width":a,"medium_large-height":a,large:af,"large-width":a,"large-height":a,"1536x1536":af,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":af,"2048x2048-width":a,"2048x2048-height":a,"medium-size":af,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"https:\u002F\u002Fwww.teller.org\u002F"},{company_name:"Titles",square_logo:d,full_logo:d,x:b,linkedin:b,website:"https:\u002F\u002Ftitles.xyz"},{company_name:"Tranched",square_logo:{ID:d_,id:d_,title:d$,filename:"logo_black.svg",filesize:7536,url:ag,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Flogo_black\u002F",alt:b,author:o,description:b,caption:b,name:d$,status:e,uploaded_to:c,date:ea,modified:ea,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:ag,"thumbnail-width":a,"thumbnail-height":a,medium:ag,"medium-width":a,"medium-height":a,medium_large:ag,"medium_large-width":a,"medium_large-height":a,large:ag,"large-width":a,"large-height":a,"1536x1536":ag,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":ag,"2048x2048-width":a,"2048x2048-height":a,"medium-size":ag,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"https:\u002F\u002Ftranched.fi\u002F"},{company_name:"triangle labs",square_logo:{ID:eb,id:eb,title:ec,filename:"triangle-labs.svg",filesize:13036,url:ah,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Ftriangle-labs\u002F",alt:b,author:k,description:b,caption:b,name:ec,status:e,uploaded_to:c,date:aJ,modified:aJ,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:ah,"thumbnail-width":a,"thumbnail-height":a,medium:ah,"medium-width":a,"medium-height":a,medium_large:ah,"medium_large-width":a,"medium_large-height":a,large:ah,"large-width":a,"large-height":a,"1536x1536":ah,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":ah,"2048x2048-width":a,"2048x2048-height":a,"medium-size":ah,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:b},{company_name:"Tweed",square_logo:{ID:ed,id:ed,title:"logo (1) - Michelle Latzer",filename:"logo-1-Michelle-Latzer.svg",filesize:2925,url:ai,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Flogo-1-michelle-latzer\u002F",alt:b,author:o,description:b,caption:b,name:"logo-1-michelle-latzer",status:e,uploaded_to:c,date:ee,modified:ee,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:ai,"thumbnail-width":a,"thumbnail-height":a,medium:ai,"medium-width":a,"medium-height":a,medium_large:ai,"medium_large-width":a,"medium_large-height":a,large:ai,"large-width":a,"large-height":a,"1536x1536":ai,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":ai,"2048x2048-width":a,"2048x2048-height":a,"medium-size":ai,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"www.paytweed.com"},{company_name:"web 3 analytics",square_logo:{ID:ef,id:ef,title:eg,filename:"web3analytics.svg",filesize:2502,url:aj,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fweb3analytics\u002F",alt:b,author:k,description:b,caption:b,name:eg,status:e,uploaded_to:c,date:aK,modified:aK,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:aj,"thumbnail-width":a,"thumbnail-height":a,medium:aj,"medium-width":a,"medium-height":a,medium_large:aj,"medium_large-width":a,"medium_large-height":a,large:aj,"large-width":a,"large-height":a,"1536x1536":aj,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":aj,"2048x2048-width":a,"2048x2048-height":a,"medium-size":aj,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"https:\u002F\u002Fwww.web3analytic.xyz\u002F"},{company_name:"zero dev",square_logo:{ID:eh,id:eh,title:ei,filename:"zero-dev.svg",filesize:2378,url:ak,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fzero-dev\u002F",alt:b,author:k,description:b,caption:b,name:ei,status:e,uploaded_to:c,date:aK,modified:aK,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:ak,"thumbnail-width":a,"thumbnail-height":a,medium:ak,"medium-width":a,"medium-height":a,medium_large:ak,"medium_large-width":a,"medium_large-height":a,large:ak,"large-width":a,"large-height":a,"1536x1536":ak,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":ak,"2048x2048-width":a,"2048x2048-height":a,"medium-size":ak,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"https:\u002F\u002Fzerodev.app\u002F"},{company_name:"zkSpin",square_logo:{ID:ej,id:ej,title:"zkSpin Logo - Justin Zhang",filename:"zkSpin-Logo-Justin-Zhang.svg",filesize:4206,url:al,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fzkspin-logo-justin-zhang\u002F",alt:b,author:o,description:b,caption:b,name:"zkspin-logo-justin-zhang",status:e,uploaded_to:c,date:ek,modified:ek,menu_order:c,mime_type:i,type:f,subtype:j,icon:g,width:c,height:c,sizes:{thumbnail:al,"thumbnail-width":a,"thumbnail-height":a,medium:al,"medium-width":a,"medium-height":a,medium_large:al,"medium_large-width":a,"medium_large-height":a,large:al,"large-width":a,"large-height":a,"1536x1536":al,"1536x1536-width":a,"1536x1536-height":a,"2048x2048":al,"2048x2048-width":a,"2048x2048-height":a,"medium-size":al,"medium-size-width":a,"medium-size-height":a}},full_logo:d,x:b,linkedin:b,website:"http:\u002F\u002Fwww.zkspin.xyz"}];cd.cta_background={ID:el,id:el,title:em,filename:"cta-backgrtound.png",filesize:509739,url:bj,link:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fcta-backgrtound\u002F",alt:b,author:k,description:b,caption:b,name:em,status:e,uploaded_to:c,date:en,modified:en,menu_order:c,mime_type:cA,type:f,subtype:cB,icon:g,width:bk,height:bl,sizes:{thumbnail:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Fcta-backgrtound-150x150.png","thumbnail-width":aC,"thumbnail-height":aC,medium:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Fcta-backgrtound-300x142.png","medium-width":cC,"medium-height":142,medium_large:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Fcta-backgrtound-768x365.png","medium_large-width":768,"medium_large-height":365,large:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Fcta-backgrtound-1024x486.png","large-width":1024,"large-height":486,"1536x1536":bj,"1536x1536-width":bk,"1536x1536-height":bl,"2048x2048":bj,"2048x2048-width":bk,"2048x2048-height":bl,"medium-size":"https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Fcta-backgrtound-600x400.png","medium-size-width":600,"medium-size-height":cD}};cd.cta_eyebrow=b;cd.cta_title=b;cd.cta_description=b;cd.cta_button=b;cd.csx_subscription_placeholder="Enter your email";cd.csx_subscription_button_text="subscribe for updates";cd.csx_subscription_thank_you="You're subscribed!";cd.vo_form_disclosure="\u003Cp\u003EThis content is provided for informational purposes only, and should not be relied upon as legal, business, investment, or tax advice. You should consult your own advisers as to those matters. References to any securities or digital assets are for illustrative purposes only, and do not constitute an investment recommendation or offer to provide investment advisory services. Furthermore, this content is not directed at nor intended for use by any investors or prospective investors, and may not under any circumstances be relied upon when making a decision to purchase or sell any asset. An offering to invest in an a16z fund will be made only by the private placement memorandum, subscription agreement, and other relevant documentation of any such fund.\u003C\u002Fp\u003E\n\u003Cp\u003ECertain information contained herein has been obtained from third-party sources, including from portfolio companies of funds managed by a16z. While taken from sources believed to be reliable, a16z has not independently verified such information and makes no representations about the current or enduring accuracy of the information or its appropriateness for a given situation. Links may include third-party advertisements; a16z has not reviewed such advertisements and does not endorse any advertising content contained therein.\u003C\u002Fp\u003E\n";cd.analytics_code_header=b;cd.banner=d;cd.banner_copy="Crypto is on the ballot. Go here for more election resources";cd.banner_link={title:b,url:"https:\u002F\u002Fwww.standwithcrypto.org\u002Fvote",target:b};cd.csx_applications_open_date="01\u002F01\u002F2025 12:00 am";cd.csx_applications_close_date="07\u002F02\u002F2025 12:00 am";cf[0]={title:"Jobs",link:"\u002Fjobs\u002Fcompanies\u002F"};cf[1]={title:"Announcements",link:"\u002Fposts\u002Ftags\u002Fannouncements"};cf[2]={title:"Legal",link:"\u002Flegal"};cf[3]={title:"Sitemap",link:"\u002Fsitemap"};cf[4]={title:"a16z.com",link:"https:\u002F\u002Fa16z.com"};cg[0]={title:"Twitter",link:"https:\u002F\u002Ftwitter.com\u002Fa16zcrypto"};cg[1]={title:"GitHub",link:"https:\u002F\u002Fgithub.com\u002Fa16z"};cg[2]={title:"YouTube",link:"https:\u002F\u002Fwww.youtube.com\u002Fchannel\u002FUCTHq3W46BiAYjKUYZq2qm-Q"};cg[3]={title:"Farcaster",link:"https:\u002F\u002Fwarpcast.com\u002Fa16zcrypto"};cg[4]={title:"LinkedIn",link:"https:\u002F\u002Fwww.linkedin.com\u002Fshowcase\u002Fa16zcrypto\u002F?viewAsMember=true"};cg[5]={title:"Instagram",link:"https:\u002F\u002Fwww.instagram.com\u002Fa16zcrypto\u002F"};ch[0]={title:"Apple Music",link:"https:\u002F\u002Fpodcasts.apple.com\u002Fus\u002Fpodcast\u002Fweb3-with-a16z-crypto\u002Fid1622312549"};ch[1]={title:"Spotify",link:"https:\u002F\u002Fopen.spotify.com\u002Fshow\u002F7pMZvsNXEnb0CYcPiDQywE"};ch[2]={title:"Amazon Music",link:"https:\u002F\u002Fmusic.amazon.com\u002Fpodcasts\u002Fc8e9bb85-11da-4498-ac00-9288f493f6db\u002Fweb3-with-a16z-crypto"};ch[3]={title:"Overcast",link:"https:\u002F\u002Fovercast.fm\u002Flogin"};ch[4]={title:"Stitcher",link:"https:\u002F\u002Fwww.stitcher.com\u002Fshow\u002Fweb3-with-a16z"};ch[5]={title:"IHeartRadio",link:"https:\u002F\u002Fwww.iheart.com\u002Fpodcast\u002F1168-web3-with-a16z-96501686\u002F"};ch[6]={title:"Pocket Casts",link:"https:\u002F\u002Fpca.st\u002F4ghx22vk"};return {data:[{articleTitle:bn,articleAuthors:[{ID:"1162",display_name:aO,first_name:"Justin",last_name:"Thaler",user_login:aP,user_email:b,linked_account:b,website:b,description:b,user_nicename:aP,type:"guest-author",nickname:b}],taxonomies:[{term_id:bo,name:aP,slug:"cap-justin-thaler",term_group:c,term_taxonomy_id:bo,taxonomy:"author",description:"Justin Thaler Justin Thaler justin-thaler 1162 ",parent:c,count:30,filter:m},{term_id:bp,name:"articles",slug:bq,term_group:c,term_taxonomy_id:bp,taxonomy:"format",description:b,parent:c,count:482,filter:m},{term_id:ay,name:br,slug:bs,term_group:c,term_taxonomy_id:ay,taxonomy:an,description:b,parent:c,count:aQ,filter:m},{term_id:az,name:r,slug:r,term_group:c,term_taxonomy_id:az,taxonomy:aq,description:b,parent:c,count:bt,filter:m},{term_id:aA,name:bu,slug:aR,term_group:c,term_taxonomy_id:aA,taxonomy:an,description:b,parent:c,count:aS,filter:m}],themes:[{term_id:ay,name:br,slug:bs,term_group:c,term_taxonomy_id:ay,taxonomy:an,description:b,parent:c,count:aQ,filter:m},{term_id:aA,name:bu,slug:aR,term_group:c,term_taxonomy_id:aA,taxonomy:an,description:b,parent:c,count:aS,filter:m}],seo:{title_tag:"FAQ on Jolt’s initial implementation - a16z crypto",meta_description:bv,canonical:bw,robots:{index:"index",follow:"follow","max-snippet":"max-snippet:-1","max-image-preview":"max-image-preview:large","max-video-preview":"max-video-preview:-1"},open_graph_locale:"en_US",open_graph_type:bq,open_graph_title:"FAQs on Jolt’s initial implementation",open_graph_description:bv,open_graph_url:bw,open_graph_images:{"https://api.a16zcrypto.com/wp-content/uploads/2024/04/Lasso_7_1200x630.jpg":{width:1200,height:630,filesize:561933,url:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F04\u002FLasso_7_1200x630.jpg",path:"\u002Fnas\u002Fcontent\u002Flive\u002Fa16zcryptocms\u002Fwp-content\u002Fuploads\u002F2024\u002F04\u002FLasso_7_1200x630.jpg",size:"full",id:"10385",alt:b,pixels:756000,type:"image\u002Fjpeg"}},open_graph_site_name:bx,estimated_reading_time_minutes:aS,twitter_card:"summary_large_image",twitter_title:b,twitter_description:b,twitter_image:b,open_graph_article_published_time:"2024-04-09T15:50:53+00:00"},hasPassword:d,id:10333,hasArticle:h,date:"2024-04-09 08:50:53",content:[{acf_fc_layout:l,paragraph:by},{acf_fc_layout:l,paragraph:bz},{acf_fc_layout:n,add_to_table_of_contents:h,title:"1. What benefits of Jolt and the sum-check protocol are not captured by the raw speed numbers from the initial implementation?"},{acf_fc_layout:l,paragraph:bA},{acf_fc_layout:n,add_to_table_of_contents:h,title:"2. Why did you choose Hyrax as the polynomial commitment scheme for the initial Jolt implementation?"},{acf_fc_layout:l,paragraph:bB},{acf_fc_layout:n,add_to_table_of_contents:h,title:"3. Can you give a rough breakdown of how Jolt works and what the prover’s costs are?"},{acf_fc_layout:l,paragraph:bC},{acf_fc_layout:n,add_to_table_of_contents:h,title:"4. How are you estimating that switching to the Binius polynomial commitment will give at least a 5x speedup?"},{acf_fc_layout:l,paragraph:bD},{acf_fc_layout:n,add_to_table_of_contents:h,title:"5. Will the Jolt prover costs (per cycle of the CPU proved) increase as you add more instructions to the primitive instruction set?"},{acf_fc_layout:l,paragraph:bE},{acf_fc_layout:n,add_to_table_of_contents:h,title:"6. Can Jolt benefit from GPUs as much as other zkVMs?"},{acf_fc_layout:l,paragraph:bF},{acf_fc_layout:n,add_to_table_of_contents:h,title:"7. How do Jolt, SP1, and RISC Zero relate to each other and the broader zkVM landscape?"},{acf_fc_layout:l,paragraph:bG},{acf_fc_layout:n,add_to_table_of_contents:h,title:"8. What are the downsides of zkVMs targeting (ostensibly) SNARK-friendly ISAs rather than pre-existing ISAs like RISC-V?"},{acf_fc_layout:l,paragraph:bH},{acf_fc_layout:n,add_to_table_of_contents:h,title:"9. In August 2023, Starkware stated that FRI is 50x faster than curve-based commitment schemes, even when committing to small values, as in Jolt. How can this be reconciled with the fact that Jolt-with-curve-based-commitments is faster than all existing zkVMs?"},{acf_fc_layout:l,paragraph:bI},{acf_fc_layout:n,add_to_table_of_contents:h,title:"10. StarkWare has described “Circle STARKs” as a breakthrough. Will Circle STARKs change the comparison between Jolt and STARK-based zkVMs?"},{acf_fc_layout:l,paragraph:bJ},{acf_fc_layout:n,add_to_table_of_contents:h,title:"11. Will STIR change the comparison between Jolt and STARK-based zkVMs?"},{acf_fc_layout:l,paragraph:bK},{acf_fc_layout:n,add_to_table_of_contents:h,title:"12. How does the space usage of the Jolt prover compare to other zkVMs?"},{acf_fc_layout:l,paragraph:bL},{acf_fc_layout:n,add_to_table_of_contents:h,title:"13. Haven&#8217;t some estimates of prover overhead in existing zkVMs been as low as 100,000? How does that not contradict your estimate of 5 million and up?"},{acf_fc_layout:l,paragraph:bM},{acf_fc_layout:n,add_to_table_of_contents:h,title:"14. What should I know about precompiles?"},{acf_fc_layout:l,paragraph:bN},{acf_fc_layout:n,add_to_table_of_contents:h,title:"15. SP1 claims to be up to 28x faster than RISC Zero on the CPU. So how can Jolt be faster than SP1 yet only 6x faster than RISC Zero?"},{acf_fc_layout:l,paragraph:bO},{acf_fc_layout:n,add_to_table_of_contents:h,title:"16. How do you plan to incorporate precompiles into Jolt?"},{acf_fc_layout:l,paragraph:bP},{acf_fc_layout:n,add_to_table_of_contents:h,title:"17. What should I know about recursion vis-à-vis Jolt and SP1?"},{acf_fc_layout:l,paragraph:bQ},{acf_fc_layout:n,add_to_table_of_contents:h,title:"18. Didn’t you recently argue that continuations for the Binius commitment scheme with Keccak as the hash function will work out fine? Why are you worried that FRI with Blake3 won’t?"},{acf_fc_layout:l,paragraph:bR},{acf_fc_layout:n,add_to_table_of_contents:h,title:"19. Doesn’t StarkWare use the Blake2s hash function in production? Doesn’t that contradict your assertion that FRI-with-Blake3 is not conducive to recursion?"},{acf_fc_layout:l,paragraph:bS},{acf_fc_layout:n,add_to_table_of_contents:h,title:"20. Isn’t Blake3 dozens of times faster than Poseidon2? Why does using Blake3 in SP1 speed up the prover by only 30%?"},{acf_fc_layout:l,paragraph:bT},{acf_fc_layout:n,add_to_table_of_contents:h,title:"21. Does recent work on “accumulation schemes without homomorphism” address your concerns about continuations for SP1-with-Blake3?"},{acf_fc_layout:l,paragraph:bU},{acf_fc_layout:n,add_to_table_of_contents:h,title:"22. Can you explain the potential benefits of accumulation\u002Ffolding schemes when Jolt is instantiated with a curve-based commitment scheme?"},{acf_fc_layout:l,paragraph:bV}],titleIndex:{"1. What benefits of Jolt and the sum-check protocol are not captured by the raw speed numbers from the initial implementation?":a,"2. Why did you choose Hyrax as the polynomial commitment scheme for the initial Jolt implementation?":bW,"3. Can you give a rough breakdown of how Jolt works and what the prover’s costs are?":bX,"4. How are you estimating that switching to the Binius polynomial commitment will give at least a 5x speedup?":bY,"5. Will the Jolt prover costs (per cycle of the CPU proved) increase as you add more instructions to the primitive instruction set?":bZ,"6. Can Jolt benefit from GPUs as much as other zkVMs?":b_,"7. How do Jolt, SP1, and RISC Zero relate to each other and the broader zkVM landscape?":b$,"8. What are the downsides of zkVMs targeting (ostensibly) SNARK-friendly ISAs rather than pre-existing ISAs like RISC-V?":8,"9. In August 2023, Starkware stated that FRI is 50x faster than curve-based commitment schemes, even when committing to small values, as in Jolt. How can this be reconciled with the fact that Jolt-with-curve-based-commitments is faster than all existing zkVMs?":9,"10. StarkWare has described “Circle STARKs” as a breakthrough. Will Circle STARKs change the comparison between Jolt and STARK-based zkVMs?":10,"11. Will STIR change the comparison between Jolt and STARK-based zkVMs?":11,"12. How does the space usage of the Jolt prover compare to other zkVMs?":12,"13. Haven&#8217;t some estimates of prover overhead in existing zkVMs been as low as 100,000? How does that not contradict your estimate of 5 million and up?":13,"14. What should I know about precompiles?":14,"15. SP1 claims to be up to 28x faster than RISC Zero on the CPU. So how can Jolt be faster than SP1 yet only 6x faster than RISC Zero?":15,"16. How do you plan to incorporate precompiles into Jolt?":16,"17. What should I know about recursion vis-à-vis Jolt and SP1?":17,"18. Didn’t you recently argue that continuations for the Binius commitment scheme with Keccak as the hash function will work out fine? Why are you worried that FRI with Blake3 won’t?":18,"19. Doesn’t StarkWare use the Blake2s hash function in production? Doesn’t that contradict your assertion that FRI-with-Blake3 is not conducive to recursion?":ca,"20. Isn’t Blake3 dozens of times faster than Poseidon2? Why does using Blake3 in SP1 speed up the prover by only 30%?":20,"21. Does recent work on “accumulation schemes without homomorphism” address your concerns about continuations for SP1-with-Blake3?":aQ,"22. Can you explain the potential benefits of accumulation/folding schemes when Jolt is instantiated with a curve-based commitment scheme?":22},taxonomiesKeys:["themes","focus-areas","series","departments","locations","stages","industries","tags","formats"],isTaxonomy:d,parsely:{version:"1.1.0",meta:{"@context":"https:\u002F\u002Fschema.org","@type":"NewsArticle",headline:bn,url:cb,mainEntityOfPage:{"@type":"WebPage","@id":cb},thumbnailUrl:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F04\u002FLASSO_7_aFAQ_1920x1080-150x150.jpg",image:{"@type":"ImageObject",url:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F04\u002FLASSO_7_aFAQ_1920x1080.jpg"},articleSection:r,author:[{"@type":"Person",name:aO}],creator:[aO],publisher:{"@type":"Organization",name:bx,logo:b},keywords:["lasso + jolt",aR],dateCreated:cc,datePublished:cc,dateModified:"2024-08-09T16:58:08Z"},rendered:"\u003Cscript type=\"application\u002Fld+json\"\u003E{\"@context\":\"https:\\\u002F\\\u002Fschema.org\",\"@type\":\"NewsArticle\",\"headline\":\"FAQ on Jolt\\u2019s initial implementation\",\"url\":\"http:\\\u002F\\\u002Fapi.a16zcrypto.com\\\u002Fposts\\\u002Farticle\\\u002Ffaqs-on-jolts-initial-implementation\\\u002F\",\"mainEntityOfPage\":{\"@type\":\"WebPage\",\"@id\":\"http:\\\u002F\\\u002Fapi.a16zcrypto.com\\\u002Fposts\\\u002Farticle\\\u002Ffaqs-on-jolts-initial-implementation\\\u002F\"},\"thumbnailUrl\":\"https:\\\u002F\\\u002Fapi.a16zcrypto.com\\\u002Fwp-content\\\u002Fuploads\\\u002F2024\\\u002F04\\\u002FLASSO_7_aFAQ_1920x1080-150x150.jpg\",\"image\":{\"@type\":\"ImageObject\",\"url\":\"https:\\\u002F\\\u002Fapi.a16zcrypto.com\\\u002Fwp-content\\\u002Fuploads\\\u002F2024\\\u002F04\\\u002FLASSO_7_aFAQ_1920x1080.jpg\"},\"articleSection\":\"research\",\"author\":[{\"@type\":\"Person\",\"name\":\"Justin Thaler\"}],\"creator\":[\"Justin Thaler\"],\"publisher\":{\"@type\":\"Organization\",\"name\":\"a16z crypto\",\"logo\":\"\"},\"keywords\":[\"lasso + jolt\",\"snarks\"],\"dateCreated\":\"2024-04-09T15:50:53Z\",\"datePublished\":\"2024-04-09T15:50:53Z\",\"dateModified\":\"2024-08-09T16:58:08Z\"}\u003C\u002Fscript\u003E",tracker_url:"https:\u002F\u002Fcdn.parsely.com\u002Fkeys\u002Fa16zcrypto.com\u002Fp.js"}}],fetch:{"data-v-73085de4:0":{fixedHeader:d,debounce:null,searching:d,settings:cd,mainMenu:[{ID:eo,post_author:aL,post_date:as,post_date_gmt:ep,post_content:b,post_title:eq,post_excerpt:b,post_status:ao,comment_status:p,ping_status:p,post_password:b,post_name:"about-2",to_ping:b,pinged:b,post_modified:as,post_modified_gmt:bm,post_content_filtered:b,post_parent:c,guid:"https:\u002F\u002Fa16zcrypto.approvemyviews.com\u002F?p=4821",menu_order:a,post_type:ap,post_mime_type:b,comment_count:q,filter:m,db_id:eo,menu_item_parent:q,object_id:"92",object:av,type:aw,type_label:ax,url:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fabout\u002F",title:eq,target:b,attr_title:b,description:b,classes:[b],xfn:b},{ID:er,post_author:aL,post_date:as,post_date_gmt:ep,post_content:b,post_title:es,post_excerpt:b,post_status:ao,comment_status:p,ping_status:p,post_password:b,post_name:"portfolio-2",to_ping:b,pinged:b,post_modified:as,post_modified_gmt:bm,post_content_filtered:b,post_parent:c,guid:"https:\u002F\u002Fa16zcrypto.approvemyviews.com\u002F?p=4822",menu_order:bW,post_type:ap,post_mime_type:b,comment_count:q,filter:m,db_id:er,menu_item_parent:q,object_id:"94",object:av,type:aw,type_label:ax,url:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fportfolio\u002F",title:es,target:b,attr_title:b,description:b,classes:[b],xfn:b},{ID:et,post_author:"1",post_date:as,post_date_gmt:"2023-01-26 15:42:16",post_content:b,post_title:eu,post_excerpt:b,post_status:ao,comment_status:p,ping_status:p,post_password:b,post_name:"content",to_ping:b,pinged:b,post_modified:as,post_modified_gmt:bm,post_content_filtered:b,post_parent:c,guid:"https:\u002F\u002Fa16z.netlify.app\u002F?p=3770",menu_order:bX,post_type:ap,post_mime_type:b,comment_count:q,filter:m,db_id:et,menu_item_parent:q,object_id:"3770",object:aM,type:aM,type_label:ev,title:eu,url:"\u002Fposts\u002F",target:b,attr_title:b,description:b,classes:[b],xfn:b},{ID:ew,post_author:aL,post_date:am,post_date_gmt:"2023-02-23 07:58:30",post_content:b,post_title:aB,post_excerpt:b,post_status:ao,comment_status:p,ping_status:p,post_password:b,post_name:aB,to_ping:b,pinged:b,post_modified:am,post_modified_gmt:aN,post_content_filtered:b,post_parent:c,guid:"https:\u002F\u002Fa16zcrypto.approvemyviews.com\u002F?p=4823",menu_order:bY,post_type:ap,post_mime_type:b,comment_count:q,filter:m,db_id:ew,menu_item_parent:q,object_id:"117",object:av,type:aw,type_label:ax,url:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fpolicy\u002F",title:aB,target:b,attr_title:b,description:b,classes:[b],xfn:b},{ID:ex,post_author:ey,post_date:am,post_date_gmt:"2023-02-27 23:58:17",post_content:b,post_title:r,post_excerpt:b,post_status:ao,comment_status:p,ping_status:p,post_password:b,post_name:r,to_ping:b,pinged:b,post_modified:am,post_modified_gmt:aN,post_content_filtered:b,post_parent:c,guid:"https:\u002F\u002Fa16z.netlify.app\u002F?p=6202",menu_order:bZ,post_type:ap,post_mime_type:b,comment_count:q,filter:m,db_id:ex,menu_item_parent:q,object_id:"107",object:av,type:aw,type_label:ax,url:"https:\u002F\u002Fapi.a16zcrypto.com\u002Fresearch\u002F",title:r,target:b,attr_title:b,description:b,classes:[b],xfn:b},{ID:ez,post_author:aL,post_date:am,post_date_gmt:"2023-02-23 07:56:09",post_content:b,post_title:eA,post_excerpt:b,post_status:ao,comment_status:p,ping_status:p,post_password:b,post_name:"4820",to_ping:b,pinged:b,post_modified:am,post_modified_gmt:aN,post_content_filtered:b,post_parent:c,guid:"https:\u002F\u002Fa16zcrypto.approvemyviews.com\u002F?p=4820",menu_order:b_,post_type:ap,post_mime_type:b,comment_count:q,filter:m,db_id:ez,menu_item_parent:q,object_id:"113",object:av,type:aw,type_label:ax,url:"https:\u002F\u002Fapi.a16zcrypto.com\u002Faccelerator\u002F",title:eA,target:b,attr_title:b,description:b,classes:[b],xfn:b},{ID:eB,post_author:ey,post_date:am,post_date_gmt:"2024-03-28 21:35:16",post_content:b,post_title:eC,post_excerpt:b,post_status:ao,comment_status:p,ping_status:p,post_password:b,post_name:"state-of-crypto",to_ping:b,pinged:b,post_modified:am,post_modified_gmt:aN,post_content_filtered:b,post_parent:c,guid:"https:\u002F\u002Fapi.a16zcrypto.com\u002F?p=10280",menu_order:b$,post_type:ap,post_mime_type:b,comment_count:q,filter:m,db_id:eB,menu_item_parent:q,object_id:"10280",object:aM,type:aM,type_label:ev,title:eC,url:"https:\u002F\u002Fa16zcrypto.com\u002Fstateofcryptoindex\u002F",target:b,attr_title:b,description:b,classes:[b],xfn:b}],contentSlideoutOpen:d},"data-v-575b5216:0":{},"data-v-575b5216:1":{},"ConstructorParagraph:0":{isLoaded:h,internalContent:by},"ConstructorParagraph:1":{isLoaded:h,internalContent:bz},"ConstructorParagraph:2":{isLoaded:h,internalContent:bA},"ConstructorParagraph:3":{isLoaded:h,internalContent:bB},"ConstructorParagraph:4":{isLoaded:h,internalContent:bC},"ConstructorParagraph:5":{isLoaded:h,internalContent:bD},"ConstructorParagraph:6":{isLoaded:h,internalContent:bE},"ConstructorParagraph:7":{isLoaded:h,internalContent:bF},"ConstructorParagraph:8":{isLoaded:h,internalContent:bG},"ConstructorParagraph:9":{isLoaded:h,internalContent:bH},"ConstructorParagraph:10":{isLoaded:h,internalContent:bI},"ConstructorParagraph:11":{isLoaded:h,internalContent:bJ},"ConstructorParagraph:12":{isLoaded:h,internalContent:bK},"ConstructorParagraph:13":{isLoaded:h,internalContent:bL},"ConstructorParagraph:14":{isLoaded:h,internalContent:bM},"ConstructorParagraph:15":{isLoaded:h,internalContent:bN},"ConstructorParagraph:16":{isLoaded:h,internalContent:bO},"ConstructorParagraph:17":{isLoaded:h,internalContent:bP},"ConstructorParagraph:18":{isLoaded:h,internalContent:bQ},"ConstructorParagraph:19":{isLoaded:h,internalContent:bR},"ConstructorParagraph:20":{isLoaded:h,internalContent:bS},"ConstructorParagraph:21":{isLoaded:h,internalContent:bT},"ConstructorParagraph:22":{isLoaded:h,internalContent:bU},"ConstructorParagraph:23":{isLoaded:h,internalContent:bV},"A16zFooter:0":{toggleDropdown:d,general_content:cd,footer_menu:cf,socials:cg,streamings:ch,puzzle:d,puzzleEnabled:h,puzzleCode1:cq,puzzleCode2:cr}},mutations:[]}}(1,"",0,false,"inherit","image","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-includes\u002Fimages\u002Fmedia\u002Fdefault.png",true,"image\u002Fsvg+xml","svg+xml","29","paragraph","raw","title","17","closed","0","research","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Fafriex.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Faxal.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Fbello.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Fcapsule.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Fchainpatrol.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F09\u002FCollar_Wordmark_Yellow-Michael-Moulton.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F09\u002Flogo_nooutline_width60-1-Elisabeth-Duijnstee.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Fdiscove.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F09\u002Fethxy-dark-J-Eth.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Fid.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Ffancraze.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Ffine.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Fflashbot.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Fformless.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Ffrens.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Ffuul.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Fgandalf.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Fgoldfinch.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Fiyk.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Fkiki.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F09\u002Fmagicblock_white-1-Andrea-Fortugno.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Fmbd.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Fmentaport.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Fmir.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Fnarval.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F09\u002FNEBRA_logo_1-Shumo-Chu.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F09\u002FFrame-27-Rishav-Mukherji.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F09\u002FNodeKit-Logo-Atomic-Abyss-1-Nick-Preszler.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Fnotion-finance.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F09\u002FOpenTrade-logo-2-David-Sutter.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Fphantom.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Fpimlico.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F09\u002FPlaymint_Logo_Export_Colour_Black-Luke-Gibson.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Fprimev.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F09\u002FRoux_logo_castiron-Lisa-Grimm.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Fshield.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F09\u002Fsiren_Logo_black-1-Andrei-Anisimov.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Fskylab.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F09\u002Ftransparent-Kaito-Yanai.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Fspring.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Fstackr.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Fteller-1.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F09\u002Flogo_black.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Ftriangle-labs.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F09\u002Flogo-1-Michelle-Latzer.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Fweb3analytics.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Fzero-dev.svg","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F09\u002FzkSpin-Logo-Justin-Zhang.svg","2024-10-10 03:10:31","post_tag","publish","nav_menu_item","category",369,"2024-10-10 03:10:30","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Fblockus.png",428,"page","post_type","Page",1945,1734,1847,"policy",150,"2024-08-28 07:31:42","2024-08-28 07:31:43","2024-08-28 07:31:44","2024-08-28 07:32:35","2024-08-28 07:32:36","2024-08-28 07:32:37","2024-08-28 07:32:38","2024-08-28 07:32:39","6","custom","2024-10-10 10:10:31","Justin Thaler","justin-thaler",21,"snarks",32,"afriex","axal","bello","blockus","capsule","id","flashbot","gandalf","iyk","mbd","mentaport","mir","narval","primev","shield","skylab","spring","stackr","https:\u002F\u002Fapi.a16zcrypto.com\u002Fwp-content\u002Fuploads\u002F2024\u002F08\u002Fcta-backgrtound.png",1312,623,"2024-10-10 10:10:30","FAQ on Jolt’s initial implementation",164,1882,"article","Lasso + Jolt","lasso-jolt",193,"SNARKs","Unpacking the technical specifics of Jolt, comparing its architecture and performance, discussing future steps","https:\u002F\u002Fapi.a16zcrypto.com\u002Fposts\u002Farticle\u002Ffaqs-on-jolts-initial-implementation\u002F","a16z crypto","\u003Cp style=\"padding-left: 40px;\"\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003EToday, a16z crypto research and engineering teams released an initial \u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fa16z\u002Fjolt\"\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003Eimplementation\u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003C\u002Fa\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003E of \u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003Ca href=\"https:\u002F\u002Fa16zcrypto.com\u002Fposts\u002Farticle\u002Fintroducing-lasso-and-jolt\u002F\"\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003EJolt\u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003C\u002Fa\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003E, a new approach to SNARK design that is already up to 2x faster than the state of the art, with more improvements still to come. See \u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003Ca href=\"https:\u002F\u002Fa16zcrypto.com\u002Fposts\u002Farticle\u002Faccelerating-the-world-computer-implementing-jolt\"\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003Ethis post\u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003C\u002Fa\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003E for a high-level overview to this body of work, as well as \u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003Ca href=\"https:\u002F\u002Fa16zcrypto.com\u002Fposts\u002Farticle\u002Fbuilding-jolt\u002F\"\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003Ethis post\u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003C\u002Fa\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003E for benchmarks and code, and \u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003Ca href=\"https:\u002F\u002Fa16zcrypto.com\u002Fposts\u002Farticle\u002Fa-new-era-in-snark-design-releasing-jolt\"\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003Ethis post\u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003C\u002Fa\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003E for technical specifics about Jolt’s architecture and performance. \u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EBelow, I unpack the technical specifics of Jolt, compare its architecture and performance with existing zkVMs, and discuss future steps planned for its development.\u003C\u002Fspan\u003E\u003C\u002Fp\u003E","\u003Ch2\u003E\u003Cspan style=\"font-weight: 400;\"\u003ECategory 1: Jolt’s performance \u003C\u002Fspan\u003E\u003C\u002Fh2\u003E\n\u003Ch3\u003E","\u003C\u002Fh3\u003E\n\u003Cp\u003E\u003Cb\u003EDeveloper benefits. \u003C\u002Fb\u003E\u003Cspan style=\"font-weight: 400;\"\u003ESince Jolt realizes the lookup singularity, it is much simpler to add new primitive instructions to Jolt’s VM compared to alternative approaches to zkVM design.\u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cb\u003EBenefits of working over a big field. \u003C\u002Fb\u003E\u003Cspan style=\"font-weight: 400;\"\u003EJolt is already the fastest zkVM to date, despite “paying” in prover time to use a 256-bit field. (Most other projects use 31-bit or 64-bit fields.) In return for \u003C\u002Fspan\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003Ealready \u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003Cspan style=\"font-weight: 400;\"\u003Epaying this price, the Jolt prover obtains the following benefits:\u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003ECheaper recursion via folding\u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003Cb\u003E. \u003C\u002Fb\u003E\u003Cspan style=\"font-weight: 400;\"\u003EMany zkVMs today use continuations, which means they break the execution of a computer program into chunks (sometimes called “shards”) and prove each chunk independently, before recursively aggregating the proofs into one. Without continuations, prover space costs become prohibitive except for toy-sized computer programs. \u003C\u002Fspan\u003E\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cp style=\"padding-left: 40px;\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003ESNARKs using curve-based commitments are amenable to very efficient aggregation via \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Feprint.iacr.org\u002F2021\u002F370.pdf\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003Efolding\u003C\u002Fspan\u003E\u003C\u002Fa\u003E \u003Ca href=\"https:\u002F\u002Feprint.iacr.org\u002F2023\u002F573\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003Eschemes\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E. The upshot is that, \u003C\u002Fspan\u003E\u003Cspan style=\"font-weight: 400;\"\u003Ealthough Jolt does not yet have recursion implemented, it stands to incur less overhead from it relative to projects like SP1 (which also does not fully have recursion implemented, despite \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fsuccinctlabs\u002Fsp1\u002Fpull\u002F457\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003Epartial progress\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E to this end). (See #22 below for details.) \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003EUsefulness even without recursion\u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003Cspan style=\"font-weight: 400;\"\u003E. Jolt proofs are 3-10 MBs today but they will fall to just a couple of dozen KBs once we add support for other curve-based polynomial commitment schemes such as \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Feprint.iacr.org\u002F2023\u002F917\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003EZeromorph\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E (see #2 below for details). zkVMs like \u003C\u002Fspan\u003E\u003Cspan style=\"font-weight: 400;\"\u003ESP1\u003C\u002Fspan\u003E\u003Cspan style=\"font-weight: 400;\"\u003E, which use FRI with a “blowup factor” of 2, cannot achieve proofs smaller than 500KBs without recursion. And unlike Jolt, FRI-based zkVMs involve superlinear-time procedures like FFTs that become a prover bottleneck if the zkVM is applied directly to large computations without continuations.   \u003C\u002Fspan\u003E\u003C\u002Fli\u003E\n\u003Cli\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003ELess overhead when moving to 64-bit data types\u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003Cb\u003E.\u003C\u002Fb\u003E \u003Cspan style=\"font-weight: 400;\"\u003EBecause Jolt’s current implementation already pays for 256-bit fields, it can represent 64-bit values in a single field element, and it can even multiply two 64-bit values together without overflowing the field modulus. This means that Jolt, once extended to handle 64-bit data types, will be less than 2x slower per instruction than when handling 32-bit data types. Hence, Jolt’s speedup over today’s zkVMs will grow larger when moving to 64-bit data types. \u003C\u002Fspan\u003E\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cp\u003E\u003Cb\u003EPerformance benefits of small fields are still to come. \u003C\u002Fb\u003E\u003Cspan style=\"font-weight: 400;\"\u003EAs discussed in \u003Ca href=\"https:\u002F\u002Fa16zcrypto.com\u002Fposts\u002Farticle\u002Fa-new-era-in-snark-design-releasing-jolt\"\u003Emy other post\u003C\u002Fa\u003E\u003C\u002Fspan\u003E\u003Cspan style=\"font-weight: 400;\"\u003E, we will switch from curve-based commitments to the hashing-based commitment scheme \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Fgitlab.com\u002FUlvetannaOSS\u002Fbinius\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003EBinius\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E, and thereby obtain a further speedup of at least 5x for Jolt (see #4 below for details). \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EThis switch \u003C\u002Fspan\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003Eonly\u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003Cspan style=\"font-weight: 400;\"\u003E works for sum-check-based SNARKs, which use multilinear rather than univariate polynomials. For example, the Binius commitment scheme exploits “tensor structure” in evaluation queries for multilinear polynomials over the so-called Lagrange basis. This tensor structure is not present for univariate polynomials over the Lagrange basis. Working over the Lagrange basis is crucial to Jolt’s performance, as it ensures that the SNARK prover only commits to small values, and avoids the need for expensive change-of-basis operations.  \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EBinius \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Feprint.iacr.org\u002F2024\u002F504.pdf\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003Egot even better\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E last week, as Diamond and Posen brought its proof size down from square root in the size of the committed polynomial to polylogarithmic. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cb\u003EMore performative precompiles. \u003C\u002Fb\u003E\u003Cspan style=\"font-weight: 400;\"\u003EToday’s zkVM deployments make heavy use of precompiles. And precompiles based on the sum-check protocol can be especially\u003C\u002Fspan\u003E \u003Cspan style=\"font-weight: 400;\"\u003Eefficient. For example, \u003C\u002Fspan\u003E\u003Cspan style=\"font-weight: 400;\"\u003Ethe \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Feprint.iacr.org\u002F2023\u002F1784\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003EBinius paper\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E describes a sum-check-based SNARK for Keccak and other standard hash functions that I expect to have a substantially faster prover than alternative approaches. Such precompiles are most efficiently incorporated into sum-check-based SNARKs like Jolt. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EAlso, many SNARK applications involve proving knowledge of elliptic-curve-based digital signatures. This is vastly more efficient if the SNARK can work directly over the \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Fzcash.github.io\u002Fhalo2\u002Fbackground\u002Fcurves.html\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003Ebase field\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E of the appropriate elliptic curve group, which Jolt-with-curve-based-commitments can do (see #14 of my \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Fa16zcrypto.com\u002Fposts\u002Farticle\u002F17-misconceptions-about-snarks\u002F\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003Eprevious post\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E for additional discussion). \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cb\u003EFuture optimizations. \u003C\u002Fb\u003E\u003Cspan style=\"font-weight: 400;\"\u003EJolt is a new approach to zkVM design that was implemented by two engineers (\u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Ftwitter.com\u002Fmoodlezoup\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003EMichael\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E and \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Ftwitter.com\u002Fsamrags_\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003ESam\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E) and a graduate student (\u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Farasua.run\u002F\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003EArasu\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E) over the course of five months. No one else besides me and \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Ftwitter.com\u002Fsrinathtv?lang=en\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003ESrinath\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E has attempted to optimize the protocol or codebase, and we have not implemented all of the \u003Ca href=\"https:\u002F\u002Fjolt.a16zcrypto.com\u002Fopts.html\"\u003Eoptimizations already identified\u003C\u002Fa\u003E\u003C\u002Fspan\u003E\u003Cspan style=\"font-weight: 400;\"\u003E. New improvements are certain to come with time and scrutiny.  \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Ch3\u003E","\u003C\u002Fh3\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EHyrax is simple, transparent, and reasonably fast for the prover. In particular, opening proofs in Hyrax do not involve \u003C\u002Fspan\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003Eany\u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003Cspan style=\"font-weight: 400;\"\u003E cryptographic work for the prover, so we knew these opening proofs would not be a prover bottleneck. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003E(More precisely, we’re currently using a stripped-down version of the \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Feprint.iacr.org\u002F2017\u002F1132.pdf\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003EHyrax-commitment\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E that is not zero-knowledge). \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EThe downside of using Hyrax is that it leads to somewhat large verifier costs. (Jolt’s proofs when using Hyrax range from a few MBs up to roughly a dozen MBs.)\u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EWe can replace Hyrax with any other commitment scheme for multilinear polynomials. In particular, we’ll add support for \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Feprint.iacr.org\u002F2023\u002F917\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003EZeromorph\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E and \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fmicrosoft\u002FNova\u002Fblob\u002Fmain\u002Fsrc\u002Fprovider\u002Fhyperkzg.rs\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003EHyperKZG\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E, which are adaptations of KZG commitments to multilinear polynomials. They have constant commitment size and logarithmic size evaluation proofs, and verification involves logarithmically many \u003Cem\u003EG\u003C\u002Fem\u003E\u003Csub\u003E1\u003C\u002Fsub\u003E operations and 3 pairing evaluations (The Zeromorph verifier has already been \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Fgithub.com\u002FMaddiaa0\u002Fhonk-verifier\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003Eimplemented in Solidity\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E for on-chain verification. A Rust implementation of its prover is \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Fgithub.com\u002Flurk-lab\u002Farecibo\u002Fblob\u002Fdev\u002Fsrc\u002Fprovider\u002Fnon_hiding_zeromorph.rs\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003Ehere\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E). \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EConcretely, this will yield a proof size of a couple dozen KBs, with no degradation in prover time compared to the current implementation. Achieving this proof size will also require switching a component of Lasso called a \u003C\u002Fspan\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003Egrand product argument\u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003Cspan style=\"font-weight: 400;\"\u003E. Jolt currently \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Feprint.iacr.org\u002F2013\u002F351.pdf\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003Euses one\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E that has log(\u003Cem\u003En\u003C\u002Fem\u003E)\u003Csup\u003E2\u003C\u002Fsup\u003E-sized proofs. A variant described in \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Feprint.iacr.org\u002F2020\u002F1275\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003ESection 6 of the Quarks paper\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E has roughly logarithmic-sized proofs, with minimal increase in prover time. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003ENaively implemented, Zeromorph and HyperKZG opening proofs could turn out to be a bottleneck for the Jolt prover, because they require the prover to commit to random field elements. But we can combine them with the (standard) technique underlying Hyrax to reduce this cost, with a modest increase in verifier work. See \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Fpeople.cs.georgetown.edu\u002Fjthaler\u002FProofsArgsAndZK.html\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003ESection 14.3 of my book\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E for the (simple) details, which involve committing to a polynomial “in smaller-sized pieces” and then using homomorphic properties to provide a single opening proof for all of the pieces. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Ch3\u003E","\u003C\u002Fh3\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EA VM does two things: \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Col\u003E\n\u003Cli style=\"font-weight: 400;\" aria-level=\"1\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003ERepeatedly execute the fetch-decode-execute logic of its instruction set architecture.\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\n\u003Cli style=\"font-weight: 400;\" aria-level=\"1\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003EPerform reads and writes to Random Access Memory (RAM).\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\n\u003C\u002Fol\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EAccordingly, Jolt has three components: \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Col\u003E\n\u003Cli style=\"font-weight: 400;\" aria-level=\"1\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003ETo handle the &#8220;execute&#8221; part of each fetch-decode-execute loop iteration, it invokes the Lasso lookup argument.\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\n\u003Cli style=\"font-weight: 400;\" aria-level=\"1\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003ETo handle reads\u002Fwrites to RAM (and to registers) it uses a memory-checking argument from \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Feprint.iacr.org\u002F2018\u002F907.pdf\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003ESpice\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E, which is closely related to Lasso itself. They are both based on &#8220;offline memory checking&#8221; techniques, the main difference being that Lasso supports read-only memory while Spice supports read-write memory, making it slightly more expensive. \u003C\u002Fspan\u003E\u003C\u002Fli\u003E\n\u003Cli style=\"font-weight: 400;\" aria-level=\"1\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003ETo handle the &#8220;fetch-decode&#8221; part of each fetch-decode-execute loop iteration, and to capture some extra constraints not directly handled by Lasso itself, there is a minimal R1CS instance (about 60 constraints per cycle of the RISC-V VM). \u003C\u002Fspan\u003E\u003C\u002Fli\u003E\n\u003C\u002Fol\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003ETo prove satisfaction of the R1CS in (3), we use \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Feprint.iacr.org\u002F2019\u002F550\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003ESpartan\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E, optimized for the highly-structured nature of the constraint system (e.g., the R1CS constraint matrices are block-diagonal with blocks of size only about 60 x 80).\u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003ERoughly, the Jolt prover today spends 25% of its time in (1), 25% in (2), and 50% in (3).\u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EAbout ⅕ of its time is spent computing commitments, and ½ of its time is spent in various invocations of the sum-check protocol. The remaining time is spread across assorted tasks like allocating memory, witness generation, serializing memory, and so forth. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EThese fractions will shift as we continue to optimize Jolt. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Ch3\u003E","\u003C\u002Fh3\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EPer #3 above, the Jolt prover currently spends about 1\u002F5 of its time computing commitments, and ½ of its time computing messages in the sum-check protocol (which mainly involves field operations: memory reads\u002Fwrites during the sum-check protocol involve a single streaming pass over a handful of arrays in each round, so the prover should not be memory bound). These are the core tasks of the Jolt prover. The remaining 30% of prover time is split across a large number of “plumbing” tasks like allocating memory and witness generation (witness generation makes up less than 2% of the Jolt prover’s runtime).\u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003ESwitching to Binius should drop the time to compute commitments by \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Fdocs.google.com\u002Fpresentation\u002Fd\u002F1vGLlcp6K0ZDLgi_zSdLCm1HrX-mmzrIJSbktdRAu99g\u002Fedit#slide=id.g2b56e456dc5_0_88\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003Ea factor of more than 10x\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E.\u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EBecause Binius works over the field GF[2\u003Csup\u003E128\u003C\u002Fsup\u003E] (rather than the scalar field of an elliptic curve like BN254, which is what Jolt uses today), field operations in the sum-check protocol will get much cheaper. Exactly how much is hardware-dependent, but \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Fwww.ulvetanna.io\u002F\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003EUlvetanna\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E is working hard to ensure the speedups are substantial. For example, on ASICs and FPGAs, it will likely be 30x or more (even without bringing in \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Fpeople.cs.georgetown.edu\u002Fjthaler\u002Fsmall-sumcheck.pdf\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003Ealgorithmic optimizations\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E that minimize the prover’s field work over small-characteristic fields). On ARM machines, the speedups should also be substantial: while Binius is targeted at the so-called \u003C\u002Fspan\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003Etower basis \u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003Cspan style=\"font-weight: 400;\"\u003Eof GF[2\u003Csup\u003E128\u003C\u002Fsup\u003E], a lot of the prover’s work can happen over the \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Fdocs.rs\u002Fpolyval\u002Flatest\u002Fpolyval\u002F#:~:text=POLYVAL%20is%20a%20GHASH%2Dlike,field%20of%20size%202%5E128.\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003EPOLYVAL basis\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E, and ARM chips support fast multiplication in this basis. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EThe biggest open question is how much we can optimize away the plumbing tasks. We haven’t yet tried hard, since they add up to only 30% of the prover’s time today. But after commitments and field operations fall in cost by 10x or more, these tasks will dominate unless optimized further. Their cost should fall by a factor of at least two simply due to switching from a 256-bit field to a 128-bit field. If it falls by much more than that, we’ll obtain an end-to-end prover speedup of over 10x. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EOne final complication is that working over fields of characteristic two makes RISC-V addition and multiplication less lookup-friendly. So these operations will be handled with bespoke SNARKs given as Protocols 5.3 and 5.5 in the \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Feprint.iacr.org\u002F2023\u002F1784.pdf\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003EBinius paper\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E, rather than via lookups. The bespoke SNARK for addition is \u003C\u002Fspan\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003Echeaper\u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003Cspan style=\"font-weight: 400;\"\u003E than Jolt’s current lookup-based approach. The bespoke SNARK for multiplication requires the prover to commit to more data than a pure-lookup-approach over a field of large characteristic. But this will be compensated for by the fact that the Binius commitment scheme itself is much faster per bit committed than a curve-based one.\u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Ch3\u003E","\u003C\u002Fh3\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EN\u003C\u002Fspan\u003E\u003Cspan style=\"font-weight: 400;\"\u003Eot meaningfully. As long as each primitive instruction is decomposable, the Jolt prover’s cost depends primarily on the \u003C\u002Fspan\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003Esize of the inputs to each instruction, \u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003Cspan style=\"font-weight: 400;\"\u003Enot on the number of instructions in the ISA. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EThis is because at each step of the computation, correct execution of the instruction that gets executed at that step is handled via a single lookup into the table containing \u003C\u002Fspan\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003Eall \u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003Cspan style=\"font-weight: 400;\"\u003Eevaluations of \u003C\u002Fspan\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003Eall \u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003Cspan style=\"font-weight: 400;\"\u003Eprimitive instructions. The size of this table grows linearly with the number of primitive instructions, but the prover’s cost in the lookup argument used (namely, \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Fa16zcrypto.com\u002Fposts\u002Farticle\u002Fintroducing-lasso-and-jolt\u002F\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003ELasso\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E) grows \u003C\u002Fspan\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003Eextremely\u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003Cspan style=\"font-weight: 400;\"\u003E slowly with the table size. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EThe \u003C\u002Fspan\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003Everifier’s \u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003Cspan style=\"font-weight: 400;\"\u003Efield work does grow with the number of primitive instructions in the ISA. But since field operations are much less expensive than cryptographic work (such as hashing or group operations, which the verifier has to do owing to use of polynomial commitment schemes), this field work will not be a verifier bottleneck for reasonable instruction set sizes. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Ch3\u003E","\u003C\u002Fh3\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EI expect so. For example, Ingonyama’s \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fingonyama-zk\u002Ficicle\u002Fblob\u002F828fc9c006a6470f2d1b4f8ba7788f79473f5589\u002Ficicle\u002FappUtils\u002Fsumcheck\u002Fsumcheck.cu#L595\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003EGPU implementation of the sum-check protocol\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E is already complete and will soon be integrated into their main GPU library, \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fingonyama-zk\u002Ficicle\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003EICICLE\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E. ICICLE already has support for the other core operation performed by the Jolt prover, namely MSMs (although it is not yet optimized for Jolt’s setting, where all values committed by the MSM are small). \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EIt’s conceivable that complications will arise when Jolt switches over to the Binius commitment scheme. Specifically, achieving very fast GF[2\u003Csup\u003E128\u003C\u002Fsup\u003E] arithmetic on a GPU may require effort (whereas, per #4 above, it is already clear that very fast operations in this field can be achieved on ARM chips, ASICs and FPGAs, etc.)\u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EAs implementations of sum-check-based SNARKs mature, there is every reason to expect  that extremely performative GPU implementations will arise, just as they have for the SNARKs that are popular today. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Ch2\u003E\u003Cspan style=\"font-weight: 400;\"\u003ECategory 2: Jolt in the broader zkVM landscape \u003C\u002Fspan\u003E\u003C\u002Fh2\u003E\n\u003Ch3\u003E","\u003C\u002Fh3\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EJolt, \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fsuccinctlabs\u002Fsp1\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003ESP1\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E, and \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Fwww.risczero.com\u002F\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003ERISC Zero\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E are all zkVMs targeting the RISC-V instruction set architecture (ISA). This is an ISA that was designed \u003C\u002Fspan\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003Ewithout \u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003Cspan style=\"font-weight: 400;\"\u003ESNARKs in mind, and a robust tooling ecosystem surrounds it. Other zkVMs target ostensibly “SNARK-friendly” ISAs (though I do not believe these other ISAs are actually any friendlier to SNARKs than RISC-V). \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EBoth SP1 and RISC Zero rely on STARK back-ends applied to AIR constraint systems. By “STARK” here, I mean a two-round polynomial IOP combined with the FRI commitment scheme for univariate polynomials. Jolt is based on different proof machinery: it uses a many-round polynomial IOP based on the sum-check protocol, combined with a commitment scheme for multilinear polynomials. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cb\u003EMore details on SP1. \u003C\u002Fb\u003E\u003Cspan style=\"font-weight: 400;\"\u003ESP1 was released in February 2024, and borrows heavily from a number of projects. Its Rust toolchain and SDK are taken from RISC Zero\u003C\u002Fspan\u003E\u003Cspan style=\"font-weight: 400;\"\u003E, as is its architecture for incorporating pre-compiles. And it uses the STARK implementation from plonky3. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EIn a nutshell, SP1’s contribution is to design AIRs implementing each RISC-V instruction, so that plonky3 can be applied to these AIRs. Even these AIRs build heavily on code from a different zkVM called \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fvalida-xyz\u002Fvalida\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003EValida\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E. (Valida targets an ISA that is inspired by RISC-V, but modifies it to be ostensibly friendlier to SNARKs.)\u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cb\u003ECPUs, GPUs, and blowup factors. \u003C\u002Fb\u003E\u003Cspan style=\"font-weight: 400;\"\u003ERISC Zero has generally focused on GPU implementation: its CPU implementation does not appear to be fully optimized. SP1 has so far focused exclusively on CPUs. The SP1 zkVM is about 5x faster than RISC Zero’s on the CPU. However, a factor of roughly 1.5x out of this 5x speedup is due to SP1 simply using a FRI \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fsuccinctlabs\u002Fsp1\u002Fblob\u002Ffe8df5e28ca1cb232edfb0729a2af2bf9b5a645f\u002Fcore\u002Fsrc\u002Futils\u002Fprove.rs#L423\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003Eblowup factor of 2\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E, rather than the \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Fgithub.com\u002Frisc0\u002Frisc0\u002Fblob\u002F5f570090d625443c6c80c03aeb81acb6d813ea7f\u002Frisc0\u002Fzkp\u002Fsrc\u002Flib.rs#L58\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003Eblowup factor of 4\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E used by RISC Zero. This makes recursion more expensive for SP1, though SP1’s current benchmarks do not “charge” the prover anything for this (since SP1 does not yet have recursion fully implemented). So the actual speedup factor of SP1 of RISC Zero on the CPU is currently closer to 3 than it is to 5. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EStill, the favorable comparison of Jolt to SP1 shows that Jolt’s speedups over prior zkVMs is not due to optimizing for the CPU over the GPU, but rather is a property of the proof system itself.\u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Ch3\u003E","\u003C\u002Fh3\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EFirst, with existing ISAs one can use existing compilers from high-level languages like Rust down to assembly code for the ISA. Those designing new “SNARK-friendly” ISAs have to build their own compilers to obtain assembly code for their custom ISA. Not only is this enormously challenging and effort-intensive (at least if one wants decent performance), it introduces a massive surface area for bugs to enter the system. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003ESecond, many “SNARK-friendly” ISAs are vastly simpler than RISC-V (fewer registers, no bitwise operations, limitations on the number of times each memory cell can be written, etc.). So each primitive instruction does much less “useful work” than a RISC-V instruction. Any given computer program requires more primitive instructions when compiled down to the custom ISA, compared to RISC-V. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EUnless each primitive instruction in the SNARK-friendly ISA is \u003C\u002Fspan\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003Eactually\u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003Cspan style=\"font-weight: 400;\"\u003E cheaper to prove than a RISC-V instruction, total prover time will be much higher, since more primitive instructions need to be proved, and each custom instruction is just as expensive to prove as RISC-V instructions.\u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EJolt is just as fast for \u003C\u002Fspan\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003Eany\u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003Cspan style=\"font-weight: 400;\"\u003E instruction set for which the instructions satisfy a natural “decomposability” property. So targeting weak instruction sets is deeply counterproductive: it weakens the amount of useful work done by each primitive instruction, without reducing the cost of invoking it.\u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EA related issue is that many projects, whether or not they’ve implemented a full-fledged zkVM, have introduced new “SNARK-friendly” programming languages to expose to developers. This has three drawbacks. First, developers have to learn a new language, and are more likely to write buggy programs until they become experts. Second, all programs used to secure anything of value should ultimately be formally verified for correctness, and just as custom ISAs require new compilers, custom DSLs will require new verification tooling. Third, if an ecosystem around a custom language fails to thrive or scale, any applications built using the language become defunct. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EIn summary, zkVM projects insisting on the use of a custom DSL for efficient compilation to an ostensibly &#8220;SNARK-friendly&#8221; VM have chosen a path riddled with drawbacks. Each design decision is a mistake–a bad VM, an inefficient SNARK used to prove that VM, a new high-level language to ease compilation to the VM, and a new compiler to perform the compilation. Each mistake adds significant inefficiency and vulnerability to errors and bugs.\u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Ch3\u003E","\u003C\u002Fh3\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EThe \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Fx.com\u002FPapiniShahar\u002Fstatus\u002F1696327688192237999?s=20\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003E50x claim\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E was later \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Fx.com\u002FEliBenSasson\u002Fstatus\u002F1753007439010558049?s=20\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003Erevised\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E downward to 10x. This adjustment came \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Ftwitter.com\u002FZac_Aztec\u002Fstatus\u002F1696654076480467015?s=20\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003Eafter\u003C\u002Fspan\u003E\u003C\u002Fa\u003E \u003Ca href=\"https:\u002F\u002Fx.com\u002FSuccinctJT\u002Fstatus\u002F1696883492380979257?s=20\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003Ecriticism\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E, \u003C\u002Fspan\u003E\u003Cspan style=\"font-weight: 400;\"\u003Ebecause the original claim overstated the costs associated with Multi-Scalar Multiplications (MSMs) by a factor of 5.\u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EBut \u003C\u002Fspan\u003E\u003Cspan style=\"font-weight: 400;\"\u003Eeven the updated claim leads to more than an order of magnitude discrepancy with the fact that Jolt-with-curve-based commitments is already the fastest zkVM to date (with many improvements still to come). How can such a huge discrepancy be explained? \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EThe answer is two-fold. First, the claim ignores that the Jolt prover commits to much less data than other zkVMs. (And due to Jolt’s use of the sum-check protocol, Jolt can’t directly use FRI, because FRI is tailored to univariate polynomials while the sum-check protocol uses multivariate ones.) For example, Jolt commits to about 1200 bits of data per step of the RISC-V CPU while RISC Zero commits to over 8500. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003ESecond, the more data the prover commits to, the more work it has to do to prove the data is well-formed. The claims ignore these large “non-commitments costs” in SNARKs that avoid the sum-check protocol. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EIn summary, StarkWare’s claims \u003C\u002Fspan\u003E\u003Cspan style=\"font-weight: 400;\"\u003Elook only at commitment time for a given amount of data, not at how much data needs to be committed, nor how much work is needed to prove the committed data is well-formed. Thus, a purported 10x slowdown (originally claimed to be 50x) turns into a \u003C\u002Fspan\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003Espeedup\u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003Cspan style=\"font-weight: 400;\"\u003E. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Ch3\u003E","\u003C\u002Fh3\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003ENo. \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Feprint.iacr.org\u002F2024\u002F278\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003ECircle STARKs\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E enable the prover to work over the “M31 field,” which is of size 2\u003Csup\u003E31 \u003C\u002Fsup\u003E&#8211; 1 and has slightly faster arithmetic than the BabyBear field currently used by SP1\u002Fplonky3 and RISC Zero. Switching to the M31 field will at best improve prover time by a modest factor of 1.4. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EStarkWare recently \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Felibensasson.blog\u002F2024\u002F03\u002F15\u002Fwhy-im-excited-by-circle-stark-and-stwo\u002F\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003Esaid\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E that they expect a Circle-Stark-based proof system called Stwo for the Cairo virtual machine to be about 100x faster than the Stone prover. But \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fa16z\u002Fjolt-stone-benchmarks\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003Eaccording to our experiments\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E, Jolt is already\u003C\u002Fspan\u003E \u003Cspan style=\"font-weight: 400;\"\u003Eover 35x faster than Stone, and that’s when comparing Stone run on programs carefully written in Cairo-VM assembly to Jolt run on programs written in Rust and compiled to RISC-V. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EAnd even Stwo will partially incorporate the techniques I am advocating for, \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Felibensasson.blog\u002F2024\u002F03\u002F15\u002Fwhy-im-excited-by-circle-stark-and-stwo\u002F\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003Evia use of\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E a \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Feprint.iacr.org\u002F2023\u002F1284\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003Esum-check-based lookup argument\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E that is inspired by Lasso. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EOn top of all of this, the 1.4x speedup promised by Circle STARKs will only come to pass if key STARK prover operations are compute-bound rather than memory-bound. The \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Feprint.iacr.org\u002F2024\u002F278\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003ECircle STARK paper\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E only implemented FFTs, and the current FFT implementation is memory-bound. No performance benefit whatsoever has yet been demonstrated under multi-threading (see Table 1 in Appendix C of the paper). \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Ch3\u003E","\u003C\u002Fh3\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003ENo. \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Feprint.iacr.org\u002F2024\u002F390\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003ESTIR\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E is an impressive result that reduces the FRI proof size over 128-bit fields by a factor of perhaps 1.5x with a modest increase in prover time. However, it does not change the fact that (contrary to widespread views) FRI and STIR, and the SNARKs that invoke them, are optimized for verification costs rather than prover time.\u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EPolynomial commitment schemes like \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Feprint.iacr.org\u002F2022\u002F1608\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003ELigero\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E\u002F\u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Feprint.iacr.org\u002F2021\u002F1043\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003EBrakedown\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E\u002F\u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Feprint.iacr.org\u002F2023\u002F1784\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003EBinius\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E have many benefits for the prover relative to FRI and STIR (see #7 of my \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Fa16zcrypto.com\u002Fposts\u002Farticle\u002Fa-technical-faq-on-lasso-jolt-and-recent-advancements-in-snark-design\u002F\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003Eprevious post\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E, and #20 below, for details). These benefits are \u003C\u002Fspan\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003Ein addition to\u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003Cspan style=\"font-weight: 400;\"\u003E the fact that FRI and STIR apply to univariate polynomials rather than multilinear ones, and so cannot be directly combined with the sum-check protocol. These are the polynomial commitment schemes that SNARK designers should use to achieve scalable provers. Similarly, curve-based commitments for multilinear polynomials are fast when combined with the right polynomial IOPs (as demonstrated by Jolt, and \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fmicrosoft\u002FNova\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003ENova\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E before it, and despite widespread misconceptions to the contrary). \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003ESNARKs optimized for verifier cost at the expense of prover time will continue to play a role, namely when proving very simple statements, or to compress proof size and verifier costs via SNARK composition just before posting a proof on-chain. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Ch3\u003E","\u003C\u002Fh3\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EToday, the Jolt prover’s space usage is roughly 5x larger than SP1’s. However, Jolt’s space usage will fall by a factor of about 8x\u003C\u002Fspan\u003E \u003Cspan style=\"font-weight: 400;\"\u003Ein the coming weeks.\u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EThe way Lasso is currently implemented in Jolt, the prover stores large vectors of 256-bit field elements, over 90% or which are 1s. We currently spend 256 bits per vector entry, even the 1s. We can instead have the prover store a “densified” representation of these vectors, that is, only store the entries that are \u003C\u002Fspan\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003Enot\u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003Cspan style=\"font-weight: 400;\"\u003E 1. Once we implement this, total prover space will fall by a factor of about 8x, and prover time will also decrease somewhat (by perhaps 10%). \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003ELong-term, I expect that the space usage of Jolt will fall \u003C\u002Fspan\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003Eanother\u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003Cspan style=\"font-weight: 400;\"\u003E factor of 10x without much impact on prover time. This space improvement will come from two places. First, switching to the Binius commitment scheme, which uses the field of size 2\u003Csup\u003E128\u003C\u002Fsup\u003E, will substantially lower the space cost of storing vectors of field elements (the maximum size of any field element will fall from 256 bits down to 128 bits, and on top of that, many field elements arising in Jolt will lie within a much smaller subfield, and hence require fewer bits to represent). Second, it has long \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Feprint.iacr.org\u002F2014\u002F846\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003Ebeen\u003C\u002Fspan\u003E\u003C\u002Fa\u003E \u003Ca href=\"https:\u002F\u002Feprint.iacr.org\u002F2020\u002F1425.pdf\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003Eknown\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E\u003Ca href=\"https:\u002F\u002Feprint.iacr.org\u002F2024\u002F524\"\u003E that\u003C\u002Fa\u003E there are space-efficient implementations of the sum-check protocol prover and \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Feprint.iacr.org\u002F2020\u002F1425.pdf\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003Evarious\u003C\u002Fspan\u003E\u003C\u002Fa\u003E \u003Ca href=\"https:\u002F\u002Feprint.iacr.org\u002F2022\u002F420.pdf\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003Epolynomial\u003C\u002Fspan\u003E\u003C\u002Fa\u003E \u003Ca href=\"https:\u002F\u002Feprint.iacr.org\u002F2022\u002F1612.pdf\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003Ecommitment\u003C\u002Fspan\u003E\u003C\u002Fa\u003E \u003Ca href=\"https:\u002F\u002Fwww.computer.org\u002Fcsdl\u002Fproceedings-article\u002Fsp\u002F2024\u002F313000a086\u002F1RjEaU3iZEY\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003Eschemes\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E. Over large-characteristic fields, the space-efficient variant of sum-check comes with a logarithmic-factor increase in prover time, but over small-characteristic fields (which Jolt will use after switching to Binius), the increase in prover time appears to be \u003Ca href=\"https:\u002F\u002Fpeople.cs.georgetown.edu\u002Fjthaler\u002Fsmall-sumcheck.pdf\"\u003Emuch smaller\u003C\u002Fa\u003E. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Ch3\u003E","\u003C\u002Fh3\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EThe right way to measure prover overhead in zkVMs depends on context. The measure that makes the most sense in the broadest array of contexts is CPU time of proving divided by CPU time of computing. By this measure, prover overhead of existing zkVMs is 5 million and up. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EIn the specific context of blockchain scalability, what matters is the monetary cost of proving a program execution vs. the monetary cost of executing the same program on-chain. Since proving is entirely centralized today, the prover can run on a cluster of GPUs, while blockchain nodes run on CPUs. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EOwing to this, some people have estimated the prover overhead of existing zkVMs by reporting the \u003C\u002Fspan\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003Eenergy cost \u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003Cspan style=\"font-weight: 400;\"\u003Eof running the zkVM prover on GPUs, normalized by the energy cost of executing the program on CPUs. This leads to estimated overheads of as low as 100,000. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EThis number isn’t wrong, but it is very specific to the context of centralized proving services for blockchain scalability. In essentially any other context, 5 million is a much more accurate estimate of how much more work proving is, relative to computing. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Ch2\u003E\u003Cspan style=\"font-weight: 400;\"\u003ECategory 3: Precompiles\u003C\u002Fspan\u003E\u003C\u002Fh2\u003E\n\u003Ch3\u003E","\u003C\u002Fh3\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EAll zkVMs introduce massive performance overhead for the prover. For example, I estimate the current version of Jolt is about 500,000 thousand times slower than simply running the RISC-V program without generating a proof of correctness (see \u003Ca href=\"https:\u002F\u002Fa16zcrypto.com\u002Fposts\u002Farticle\u002Fa-new-era-in-snark-design-releasing-jolt\"\u003Emy companion post\u003C\u002Fa\u003E\u003C\u002Fspan\u003E\u003Cspan style=\"font-weight: 400;\"\u003E for details). \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EIt&#8217;s almost always better for performance to hand-design a protocol for a specific computation like SHA2 or Keccak evaluation, or verifying elliptic curve digital signatures, than it is to write a Rust program, compile it down to the assembly language of a zkVM, and prove correct execution of the zkVM. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EThese special-purpose protocols are called precompiles (also known as “built-ins&#8221; or “gadgets”). \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003ESo to maximize performance, every zkVM should use precompiles for operations that occur over and over again in SNARK applications. As of today, it&#8217;s the only way performance is going to be acceptable in most settings. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EBut there are also major downsides to relying on precompiles. For example, today’s precompiles are all hand-specified circuits or constraint systems (AIRs in the case of SP1\u002Fplonky3, RISC Zero, or Cairo). This is\u003C\u002Fspan\u003E \u003Cspan style=\"font-weight: 400;\"\u003Eexactly the error-prone and time-intensive process that zkVMs are meant to obviate. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EThere will be a temptation to paper over the massive performance overheads of zkVMs with overreliance on precompiles. But this risks putting us right back where we are today, with security vulnerabilities everywhere and thousands of human hours spent grinding out constraint specifications. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003ELong-term, zkVMs will grow fast enough that precompiles can be completely avoided in many applications. Precompiles for a handful of pervasive operations will persist, and these will be formally verified for correctness. This will be analogous to how new generations of CPUs come with new primitive instructions baked into the hardware to accelerate common cryptographic operations. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EThese pervasive precompiles will include a handful of hash functions and digital signature schemes, and commonly-occurring operations in specific application domains, like popular non-linearities and matrix multiplication for machine learning applications. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Ch3\u003E","\u003C\u002Fh3\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003ESP1 \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Fblog.succinct.xyz\u002Fintroducing-sp1\u002F\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003Ereports\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E speedups over RISC Zero ranging from about 4x to 28x depending on the benchmark. However, any speedup over about 5x is not due to improvements in the zkVM, but rather to better precompiles. Advances in precompiles are orthogonal to advances in zkVMs, and any zkVM can benefit from them. So, for example, RISC Zero can directly benefit from SP1\u002Fplonky3’s better precompiles, just as SP1 itself does. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EOur benchmarks seek to assess zkVMs and hence omit the use of precompiles. (Also, extending Jolt to support precompiles is near-term future work, see #16\u003C\u002Fspan\u003E\u003Cb\u003E \u003C\u002Fb\u003E\u003Cspan style=\"font-weight: 400;\"\u003Ebelow).  \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003ELong-term, precompiles based on the sum-check protocol will be the fastest, and these integrate most nicely with sum-check-based zkVMs like Jolt. The quintessential examples of such a precompile is the \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Fpeople.cs.georgetown.edu\u002Fjthaler\u002Fblogpost.pdf\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003Esuper-efficient sum-check-based protocol\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E for matrix multiplication \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Feprint.iacr.org\u002F2013\u002F351.pdf\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003Efrom 2013\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E or for FFTs from \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Feprint.iacr.org\u002F2021\u002F673.pdf\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003EzkCNN\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E. Another is the sum-check-based SNARK for Keccak from the \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Feprint.iacr.org\u002F2023\u002F1784\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003EBinius paper\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E, which once fully optimized, I expect to be state-of-the-art by a significant margin. (A preliminary implementation is already\u003C\u002Fspan\u003E\u003Cspan style=\"font-weight: 400;\"\u003E 2x faster than the \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Fgithub.com\u002FPlonky3\u002FPlonky3\u002Ftree\u002Fmain\u002Fkeccak-air\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003EKeccak precompile\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E from plonky3, with major performance improvements still to be implemented.)\u003C\u002Fspan\u003E\u003Cspan style=\"font-weight: 400;\"\u003E \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EIn addition to the above, RISC Zero has experienced roughly a 2x improvement on CPUs since the initial release of SP1 (presumably due to the optimizations \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Fwww.risczero.com\u002Fblog\u002Fzkvm-performance-upgrades-roadmap-q1-q2-2024\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003Esummarized here\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E). \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Ch3\u003E","\u003C\u002Fh3\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EIncorporating precompiles into Jolt is essential to achieve developer adoption, since performance of all zkVMs, Jolt included, is simply too slow today without them (though Jolt \u003C\u002Fspan\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003Ewithout\u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003Cspan style=\"font-weight: 400;\"\u003E pre-compiles is faster than most existing zkVMs \u003C\u002Fspan\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003Ewith\u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003Cspan style=\"font-weight: 400;\"\u003E precompiles). \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EThe simplest approach is to have the prover &#8220;collect&#8221; all the inputs to the various invocations of the precompile together and apply (a data-parallel version) of the precompile to the collected inputs. \u003C\u002Fspan\u003E\u003Cspan style=\"font-weight: 400;\"\u003EEven this collection step can likely be avoided using techniques \u003Ca href=\"https:\u002F\u002Fjolt.a16zcrypto.com\u002Fhow\u002Fjolt.html#subtable-flags\"\u003Ealready incorporated\u003C\u002Fa\u003E into the current Jolt implementation\u003C\u002Fspan\u003E\u003Cspan style=\"font-weight: 400;\"\u003E. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EIf the precompile consists of a hand-specified constraint system (which is how the current generation of zkVMs implements precompiles), we would have developers specify the constraint system in an appropriate constraint specification language, and then apply a back-end for that constraint system to prove satisfiability. Today’s zkVMs all use AIR as the constraint system. We can\u003C\u002Fspan\u003E \u003Cspan style=\"font-weight: 400;\"\u003Ereuse these precompiles by applying \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Feprint.iacr.org\u002F2023\u002F552\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003EBabySpartan\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E or \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Feprint.iacr.org\u002F2023\u002F552\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003ESuperSpartan\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E (our sum-check-based SNARKs for AIR and Plonkish constraint systems) to prove their satisfiability. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003ELong-term, the fastest precompiles will be special-purpose sum-check-based SNARKs that avoid constraint systems entirely. In this case, we’d probably have developers specify them by expressing the prover and verifier directly, in Rust.\u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Ch2\u003E\u003Cspan style=\"font-weight: 400;\"\u003ECategory 4: Recursion and continuations\u003C\u002Fspan\u003E\u003C\u002Fh2\u003E\n\u003Ch3\u003E","\u003C\u002Fh3\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003ERecall that many zkVMs today use continuations, which means they break the execution of a computer program into chunks and prove each chunk independently before recursively aggregating the proofs into one.\u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cb\u003ESP1 and continuations. \u003C\u002Fb\u003E\u003Cspan style=\"font-weight: 400;\"\u003ESP1\u002Fplonky3 does not have the recursive aggregation step implemented (despite \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fsuccinctlabs\u002Fsp1\u002Fpull\u002F457\"\u003Epartial progress\u003C\u002Fa\u003E to this end). SP1 simply outputs one proof per chunk. This means SP1 currently has huge verifier costs–the proof for \u003C\u002Fspan\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003Eeach chunk\u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003Cspan style=\"font-weight: 400;\"\u003E is over 500KB, and there is one chunk for every 2\u003Csup\u003E19\u003C\u002Fsup\u003E cycles of the RISC-V CPU. So proofs are dozens of MBs in total for programs that run for 10 million cycles and up. The verifier has to hash most of the data in the proof.\u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EAccordingly, SP1’s benchmarks charge the prover \u003C\u002Fspan\u003E\u003Cspan style=\"font-weight: 400;\"\u003Enothing\u003C\u002Fspan\u003E\u003Cspan style=\"font-weight: 400;\"\u003E for recursive proof aggregation (i.e., it’s simply not done), even though before it’s ever actually deployed, recursion will have to be enabled to reduce verifier costs (see #1 above for further discussion). \u003C\u002Fspan\u003E\u003Cspan style=\"font-weight: 400;\"\u003EThis is not entirely unreasonable since the benchmarks use Poseidon2 as the hash function, which is “recursion-friendly.” So while implementing recursion would cost the prover something, it should not be prohibitive. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EHowever, there may still be challenges. For example, some have \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Fx.com\u002FQEDProtocol\u002Fstatus\u002F1772305889153720722?s=20\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003Eturned to\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E the slower plonky2 system to obtain a recursive variant of plonky3, perhaps \u003C\u002Fspan\u003E\u003Cspan style=\"font-weight: 400;\"\u003Edue to limitations posed by plonky3’s exclusive support for AIR constraint systems\u003C\u002Fspan\u003E\u003Cspan style=\"font-weight: 400;\"\u003E. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EAnd SP1 is configured to aggressively optimize prover time at the cost of making recursion more expensive. The default SP1 “shard size” is 2\u003Csup\u003E19\u003C\u002Fsup\u003E and the FRI “blowup factor” is 2, while RISC Zero has a default shard size of 2\u003Csup\u003E20\u003C\u002Fsup\u003E and a FRI blowup factor of 4. The net effect is that recursive proving in SP1 would be about four times more expensive for RISC Zero, yet SP1’s benchmarks charge the prover nothing for this.\u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003ESuccinct has proposed that further prover speedups will be had by using the Blake3 hash function instead of Poseidon2. However, this would only speed the prover up by about 30%.\u003C\u002Fspan\u003E \u003Cspan style=\"font-weight: 400;\"\u003EIn addition, it’s not at all clear that Blake3 can be used without recursive proof aggregation becoming a major bottleneck. Proof aggregation for SP1 requires the prover to prove that it correctly hashed well over 500 KB of data per chunk. Current precompiles for Blake3 are nowhere near fast enough to keep this from being a major bottleneck. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cb\u003EJolt and continuations. \u003C\u002Fb\u003E\u003Cspan style=\"font-weight: 400;\"\u003ELike SP1, Jolt does not yet have continuations implemented. But since Jolt’s implementation already “pays” to use a 256-bit field and elliptic-curve-based commitments, Jolt is amenable to fast continuations via folding (see #1 above and #22 below for additional discussion). Once Jolt switches to the Binius commitment scheme, continuations will be implemented via recursive proof aggregation rather than folding. Recursion will not be a prover bottleneck, as described in my \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Fa16zcrypto.com\u002Fposts\u002Farticle\u002Fboosting-lassojolt\u002F\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003Eprevious post\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E (even more so now that the proof size of Binius \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Feprint.iacr.org\u002F2024\u002F504.pdf\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003Ehas fallen\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E to polylogarithmic).   \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cb\u003EComplications in comparing performance\u003C\u002Fb\u003E\u003Cspan style=\"font-weight: 400;\"\u003E. Jolt today does not split computations into chunks. SP1 does, but does not recursively aggregate the proofs, so its proofs grow very large when there are many chunks. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EJolt is over 3x faster than SP1 today when both are run with a single chunk, but the speedup falls as the number of chunks SP1 uses increases. This is because SP1’s “intra-chunk” parallelization is not fully optimized (it will soon be improved, though: an interpolation procedure done by the prover is parallelizable but has not yet been parallelized). In contrast, inter-chunk parallelization is trivial (i.e., the prover can work on many chunks at once, independently generating the proof for each chunk). \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EIntra-chunk parallelization is more challenging and less perfect than inter-chunk parallelization (where the prover trivially proves multiple chunks in parallel). Today, Jolt does not take advantage of inter-chunk parallelization at all (since Jolt only runs on one chunk). Hence, Jolt may see modest performance improvements once it, too, splits big computations into many chunks. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Ch3\u003E","\u003C\u002Fh3\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EThe \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Feprint.iacr.org\u002F2023\u002F1784\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003EBinius paper\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E gives a very fast SNARK for Keccak, which uses the sum-check protocol, combined with the Binius commitment scheme. This protocol, once fully optimized, will be much faster than non-sum-check-based SNARKs for Keccak.\u003C\u002Fspan\u003E\u003Cspan style=\"font-weight: 400;\"\u003E This very high performance will be needed for continuations to work out, at least without resorting to huge shard sizes that lead to many GBs of prover space and other performance bottlenecks. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Ch3\u003E","\u003C\u002Fh3\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EStarkWare builds Merkle trees \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fstarkware-libs\u002Fstone-prover\u002Fblob\u002F7ac17c8ba63a789604350e501558ef0ab990fd88\u002Fsrc\u002Fstarkware\u002Fcrypt_tools\u002Finvoke.h#L46\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003Eusing\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E Blake2s as the hash function at a handful of “big” layers of the Merkle tree, and a slow, “SNARK-friendly” hash function at the other layers. This way, most hashes along any particular root-to-leaf authentication path are “SNARK-friendly” (keeping recursion cheap), but the prover time required to build the Merkle tree is dominated by the handful of big layers where the faster hash function is used.\u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EHowever, most STARK-based zkVMs store lengthy vectors of field elements at each leaf of the Merkle tree. In this context, StarkWare’s technique of “Blake2s-hash only the big layers” is not very helpful, because most of the verifier’s work involves applying Blake2s to vectors stored at the leaves.\u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EStarkWare’s production prover is dozens of times slower than Jolt, even when running it on hand-written Cairo-VM assembly. The fact that it uses Blake2s in conjunction with recursion does not mean that this would be helpful in other zkVMs. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Ch3\u003E","\u003C\u002Fh3\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EBlake3 is fastest when hashing large files. The Merkle trees used in SP1 store moderately-sized vectors at the leaves. These are, effectively, small files, which each need to be hashed. In this context, Blake3 appears to only be about 3x-4x faster than Poseidon2. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EThis is yet another benefit for the prover of the \u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Feprint.iacr.org\u002F2022\u002F1608\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003ELigero\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E\u002F\u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Feprint.iacr.org\u002F2021\u002F1043\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003EBrakedown\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E\u002F\u003C\u002Fspan\u003E\u003Ca href=\"https:\u002F\u002Feprint.iacr.org\u002F2023\u002F1784\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003EBinius\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E commitment schemes compared to FRI: with the Ligero\u002FBrakedown\u002FBinius commitments, there are always large vectors at the leaves of the Merkle tree. This allows bigger reductions in hashing time when using hash functions like Blake3. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EMerkle hashing is about 30% of the SP1 prover time when using Poseidon2 and about 10% when using Blake3. So a 3x-4x reduction in hashing time translates to only about a 30% reduction in total prover time. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EThis highlights that using Blake3 rather than Poseidon2 reduces commitment time, but does nothing to lower the time to prove well-formedness of the committed data. Sum-check-based SNARKs like Jolt are faster not only because less committed data means faster computation of the commitments, but also because proving that data is well-formed is cheaper when there’s less of it. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Ch3\u003E","\u003C\u002Fh3\u003E\n\u003Cdiv\u003E\n\u003Cdiv\u003E\n\u003Cp\u003ENo. Implementing continuations via the \u003Ca href=\"https:\u002F\u002Feprint.iacr.org\u002F2024\u002F474\" target=\"_blank\" rel=\"noopener\" data-saferedirecturl=\"https:\u002F\u002Fwww.google.com\u002Furl?q=https:\u002F\u002Feprint.iacr.org\u002F2024\u002F474&amp;source=gmail&amp;ust=1715687206455000&amp;usg=AOvVaw1PdhCxNOeWBND3XlB0Dl3T\"\u003Enewly proposed accumulation scheme\u003C\u002Fa\u003E will be worse for the prover than using Poseidon2 and applying naive SNARK recursion (meaning, recursion in the style of plonky2, or RISC Zero continuations).\u003C\u002Fp\u003E\n\u003Cp\u003EThis is for at least two reasons. First, every time \u003Cem\u003Em\u003C\u002Fem\u003E shards are aggregated together, the new scheme requires the prover to compute and commit to extra data. This extra data does not need to be committed in existing accumulation schemes based on homomorphic commitments. The extra data is a random linear combination of the data committed for each shard individually, where the random coefficients come from a “big field” (at least 128 bits), even when the data being combined all comes from a small field. So simply computing this linear combination slows down the prover by a significant factor, likely more than the 30% increase that would come from using Poseidon2 to ensure naive recursion is not a bottleneck.\u003C\u002Fp\u003E\n\u003Cp\u003ESecond, the main reason to implement continuations is to control prover space when proving large computations, but with the new accumulation proposal, there are limitations on how small prover space can be. This is because the newly proposed accumulation scheme still needs the prover to prove that it correctly computed many hash evaluations, specifically \u003Cem\u003EO\u003C\u002Fem\u003E(\u003Cem\u003Ed\u003C\u002Fem\u003Eλ log\u003Cem\u003En\u003C\u002Fem\u003E) of them where \u003Cem\u003Ed\u003C\u002Fem\u003E is the depth of the accumulation and λ is the security parameter. For comparison, naive recursion with STIR involves proving \u003Cem\u003EO\u003C\u002Fem\u003E(λ log(\u003Cem\u003En\u003C\u002Fem\u003E) loglog(\u003Cem\u003En\u003C\u002Fem\u003E)) hashes. So the improvement of the new folding scheme relative to naive recursion is a \u003Cem\u003Ed\u003C\u002Fem\u003E\u002Floglog(\u003Cem\u003En\u003C\u002Fem\u003E) factor, which means it is actually worse if \u003Cem\u003Ed\u003C\u002Fem\u003E is larger than loglog\u003Cem\u003En\u003C\u002Fem\u003E, and even for constant \u003Cem\u003Ed\u003C\u002Fem\u003E it is better only by a small factor.\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cem\u003Ed\u003C\u002Fem\u003E can be kept small in one of two ways. One way is to accumulate a very large amount of committed data &#8220;at once,&#8221; but this keeps the prover&#8217;s space large. The other is to use a hybrid scheme — accumulate for a small number of levels without ever accumulating a lot of data &#8220;all at once,&#8221; and then apply brute-force recursion to aggregate the results of those accumulations. If Blake3 is impractical for naive recursion with STIR, it is likely also impractical for the hybrid accumulation scheme, as the reduction in hashes being proven relative to STIR is small. And in this hybrid scheme, the prover inherits the space bottleneck of brute-force recursion rather than standard homomorphic folding schemes: namely, recursively proving that STIR or FRI verification was done correctly.\u003C\u002Fp\u003E\n\u003C\u002Fdiv\u003E\n\u003C\u002Fdiv\u003E","\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EAs discussed above, continuations refers to chopping up the execution of the VM into chunks, each consisting of several million cycles, applying Jolt to each chunk individually, and then aggregating the chunks together. And there are two high-level approaches to aggregating the chunks together. One is &#8220;naive recursion&#8221;: this means producing a full Jolt proof per chunk, but rather than outputting all those proofs (which would lead to large proofs and high verifier costs, as in SP1 today), instead the prover recursively proves it knows those proofs. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EThe other approach is folding (sometimes called accumulation). The main benefit of folding over the naive-recursion approach is that with folding, you can omit the evaluation proof for all committed polynomials, instead using the homomorphism property of curve-based commitments to aggregate all committed polynomials across all chunks into a single committed polynomial. Omitting these evaluation proofs has two potential benefits: (1) the prover never has to compute them and (2) the Jolt verifier, which has to be expressed via an appropriate constraint system (or RISC-V program) to implement recursion, never has to check them. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003EJolt makes sure these evaluation proofs are not a bottleneck for the prover, so (1) isn&#8217;t a big deal. But (2) matters: it’s exactly the reason that I do not think recursion can be implemented for SP1-with-Blake3 without significant costs. Due to (2), folding can help ensure recursion isn&#8217;t a meaningful contributor to the prover&#8217;s costs. It can also be useful for minimizing prover space, by enabling the chunks to be much smaller without recursion becoming a prover bottleneck. \u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003E***\u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fa16zcrypto.com\u002Fteam\u002Fjustin-thaler\"\u003E\u003Cspan style=\"font-weight: 400;\"\u003EJustin Thaler\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cspan style=\"font-weight: 400;\"\u003E is Research Partner at a16z and an Associate Professor in the Department of Computer Science at Georgetown University. His research interests include verifiable computing, complexity theory, and algorithms for massive data sets.\u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cspan style=\"font-weight: 400;\"\u003E***\u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003EThe views expressed here are those of the individual AH Capital Management, L.L.C. (“a16z”) personnel quoted and are not the views of a16z or its affiliates. Certain information contained in here has been obtained from third-party sources, including from portfolio companies of funds managed by a16z. While taken from sources believed to be reliable, a16z has not independently verified such information and makes no representations about the current or enduring accuracy of the information or its appropriateness for a given situation. In addition, this content may include third-party advertisements; a16z has not reviewed such advertisements and does not endorse any advertising content contained therein.\u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003EThis content is provided for informational purposes only, and should not be relied upon as legal, business, investment, or tax advice. You should consult your own advisers as to those matters. References to any securities or digital assets are for illustrative purposes only, and do not constitute an investment recommendation or offer to provide investment advisory services. Furthermore, this content is not directed at nor intended for use by any investors or prospective investors, and may not under any circumstances be relied upon when making a decision to invest in any fund managed by a16z. (An offering to invest in an a16z fund will be made only by the private placement memorandum, subscription agreement, and other relevant documentation of any such fund and should be read in their entirety.) Any investments or portfolio companies mentioned, referred to, or described are not representative of all investments in vehicles managed by a16z, and there can be no assurance that the investments will be profitable or that other investments made in the future will have similar characteristics or results. A list of investments made by funds managed by Andreessen Horowitz (excluding investments for which the issuer has not provided permission for a16z to disclose publicly as well as unannounced investments in publicly traded digital assets) is available at https:\u002F\u002Fa16z.com\u002Finvestment-list\u002F.\u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003ECharts and graphs provided within are for informational purposes solely and should not be relied upon when making any investment decision. \u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003Ci\u003E\u003Cspan style=\"font-weight: 400;\"\u003EPast performance is not indicative of future results. The content speaks only as of the date indicated. Any projections, estimates, forecasts, targets, prospects, and\u002For opinions expressed in these materials are subject to change without notice and may differ or be contrary to opinions expressed by others. Please see https:\u002F\u002Fa16z.com\u002Fdisclosures\u002F for additional important information.\u003C\u002Fspan\u003E\u003C\u002Fi\u003E\u003Cspan style=\"font-weight: 400;\"\u003E \u003C\u002Fspan\u003E\u003C\u002Fp\u003E",2,3,4,5,6,7,19,"http:\u002F\u002Fapi.a16zcrypto.com\u002Fposts\u002Farticle\u002Ffaqs-on-jolts-initial-implementation\u002F","2024-04-09T15:50:53Z",{},"Enter email address",Array(5),Array(6),Array(7),1732,1733,1735,1801,"decentralization",1841,1793,"security","WTUVKUCXZLYAD\u003Cbr \u002F\u003EGGCMUGJX","AGO + TO = 404",11889,"2024-08-28 07:23:50",11891,"2024-08-28 07:24:22",11890,"2024-08-28 07:24:09",11892,"2024-08-28 07:24:41","image\u002Fpng","png",300,400,11893,"2024-08-28 07:24:55",11894,"chainpatrol","2024-08-28 07:25:09",12010,"2024-09-03 23:22:08",12009,"2024-09-03 23:18:44",11895,"discove","2024-08-28 07:25:23",12011,"2024-09-03 23:23:25",11896,"2024-08-28 07:25:59",11897,"fancraze","2024-08-28 07:26:17",11899,"fine","2024-08-28 07:27:51",11900,"2024-08-28 07:28:30",11898,"formless","2024-08-28 07:26:37",11901,"frens","2024-08-28 07:28:57",11902,"fuul","2024-08-28 07:29:31",11903,"2024-08-28 07:29:48",11904,"2024-08-28 07:30:10",11906,"2024-08-28 07:30:35","kiki",11905,"2024-08-28 07:30:29",12012,"2024-09-03 23:28:51",11907,11908,11909,11910,12013,"2024-09-03 23:30:15",12014,"2024-09-03 23:31:13",12015,"2024-09-03 23:31:59",11911,"notion-finance",12016,"2024-09-03 23:33:28","phantom",11912,"pimlico",11913,12017,11879,11914,12018,11915,12019,"2024-09-03 23:36:41",11916,12020,"2024-09-03 23:37:29",11917,11918,"teller",11919,12021,"logo_black","2024-09-03 23:40:11",11920,"triangle-labs",12022,"2024-09-03 23:41:18",11921,"web3analytics",11922,"zero-dev",12023,"2024-09-03 23:42:11",11924,"cta-backgrtound","2024-08-28 07:35:56",4821,"2023-02-23 07:58:29","about",4822,"portfolio",3770,"posts","Custom Link",4823,6202,"12",4820,"accelerator",10280,"crypto index")));